{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Analytics for Health - Task 2.4: Final Clustering Evaluation and Comparison\n",
        "\n",
        "## Overview\n",
        "This notebook performs final evaluation and comparison of all clustering methods:\n",
        "- K-means clustering\n",
        "- Density-based clustering (DBSCAN)\n",
        "- Hierarchical clustering\n",
        "\n",
        "## Objectives\n",
        "- Compare clustering results from all three methods\n",
        "- Evaluate and compare performance metrics\n",
        "- Visualize differences between clustering approaches\n",
        "- Select the best clustering approach for the dataset\n",
        "- Discuss advantages and disadvantages of each method\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set up file paths\n",
        "notebook_dir = Path.cwd().resolve()\n",
        "data_path = (notebook_dir / '..' / 'Data').resolve()\n",
        "plots_dir = (notebook_dir / '..' / 'plots').resolve()\n",
        "plots_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "print(f\"Data path: {data_path}\")\n",
        "print(f\"Plots directory: {plots_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data and Clustering Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load original data\n",
        "df = pd.read_csv(data_path / '1.2.2_prepared_patient_profile.csv')\n",
        "print(f\"Loaded patient profile: {df.shape[0]:,} subjects × {df.shape[1]} features\")\n",
        "\n",
        "# Get numeric features\n",
        "numeric_features = [col for col in df.columns if col != 'subject_id' and df[col].dtype in [np.float64, np.int64]]\n",
        "\n",
        "# Prepare data\n",
        "X = df[numeric_features].copy()\n",
        "X = X.fillna(X.mean())\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Load clustering results\n",
        "try:\n",
        "    df_kmeans = pd.read_csv(data_path / '2.1_kmeans_clustered_data.csv')\n",
        "    labels_kmeans = df_kmeans['cluster'].values\n",
        "    print(f\"\\n✓ Loaded K-means results: {len(np.unique(labels_kmeans))} clusters\")\n",
        "except FileNotFoundError:\n",
        "    print(\"\\n✗ K-means results not found. Run 2.1_kmeans_clustering.ipynb first.\")\n",
        "    labels_kmeans = None\n",
        "\n",
        "try:\n",
        "    df_dbscan = pd.read_csv(data_path / '2.2_dbscan_clustered_data.csv')\n",
        "    labels_dbscan = df_dbscan['cluster'].values\n",
        "    n_clusters_dbscan = len(np.unique(labels_dbscan[labels_dbscan != -1]))\n",
        "    n_noise_dbscan = np.sum(labels_dbscan == -1)\n",
        "    print(f\"✓ Loaded DBSCAN results: {n_clusters_dbscan} clusters, {n_noise_dbscan} noise points\")\n",
        "except FileNotFoundError:\n",
        "    print(\"✗ DBSCAN results not found. Run 2.2_density_based_clustering.ipynb first.\")\n",
        "    labels_dbscan = None\n",
        "\n",
        "try:\n",
        "    df_hierarchical = pd.read_csv(data_path / '2.3_hierarchical_clustered_data.csv')\n",
        "    labels_hierarchical = df_hierarchical['cluster'].values\n",
        "    print(f\"✓ Loaded Hierarchical results: {len(np.unique(labels_hierarchical))} clusters\")\n",
        "except FileNotFoundError:\n",
        "    print(\"✗ Hierarchical results not found. Run 2.3_hierarchical_clustering.ipynb first.\")\n",
        "    labels_hierarchical = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Comprehensive Evaluation Metrics Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute evaluation metrics for each method\n",
        "evaluation_results = []\n",
        "\n",
        "methods = {\n",
        "    'K-means': labels_kmeans,\n",
        "    'DBSCAN': labels_dbscan,\n",
        "    'Hierarchical': labels_hierarchical\n",
        "}\n",
        "\n",
        "for method_name, labels in methods.items():\n",
        "    if labels is not None:\n",
        "        # Basic statistics\n",
        "        unique_labels = np.unique(labels)\n",
        "        n_clusters = len(unique_labels[unique_labels != -1]) if -1 in unique_labels else len(unique_labels)\n",
        "        n_noise = np.sum(labels == -1) if -1 in labels else 0\n",
        "        \n",
        "        # Compute metrics (excluding noise for DBSCAN)\n",
        "        if n_clusters >= 2:\n",
        "            if -1 in labels:\n",
        "                # DBSCAN: exclude noise points\n",
        "                non_noise_mask = labels != -1\n",
        "                if np.sum(non_noise_mask) > 1:\n",
        "                    silhouette = silhouette_score(X_scaled[non_noise_mask], labels[non_noise_mask])\n",
        "                    davies_bouldin = davies_bouldin_score(X_scaled[non_noise_mask], labels[non_noise_mask])\n",
        "                    calinski_harabasz = calinski_harabasz_score(X_scaled[non_noise_mask], labels[non_noise_mask])\n",
        "                else:\n",
        "                    silhouette = -1\n",
        "                    davies_bouldin = np.inf\n",
        "                    calinski_harabasz = 0\n",
        "            else:\n",
        "                # K-means and Hierarchical: use all points\n",
        "                silhouette = silhouette_score(X_scaled, labels)\n",
        "                davies_bouldin = davies_bouldin_score(X_scaled, labels)\n",
        "                calinski_harabasz = calinski_harabasz_score(X_scaled, labels)\n",
        "        else:\n",
        "            silhouette = -1\n",
        "            davies_bouldin = np.inf\n",
        "            calinski_harabasz = 0\n",
        "        \n",
        "        evaluation_results.append({\n",
        "            'Method': method_name,\n",
        "            'N_Clusters': n_clusters,\n",
        "            'N_Noise': n_noise,\n",
        "            'Noise_Ratio': n_noise / len(labels) if len(labels) > 0 else 0,\n",
        "            'Silhouette_Score': silhouette,\n",
        "            'Davies_Bouldin': davies_bouldin,\n",
        "            'Calinski_Harabasz': calinski_harabasz\n",
        "        })\n",
        "\n",
        "evaluation_df = pd.DataFrame(evaluation_results)\n",
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE EVALUATION METRICS\")\n",
        "print(\"=\"*80)\n",
        "print(evaluation_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comparison of metrics\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Silhouette Score\n",
        "ax = axes[0, 0]\n",
        "valid_data = evaluation_df[evaluation_df['Silhouette_Score'] >= 0]\n",
        "if len(valid_data) > 0:\n",
        "    bars = ax.bar(valid_data['Method'], valid_data['Silhouette_Score'], \n",
        "                  color=['steelblue', 'coral', 'mediumseagreen'][:len(valid_data)])\n",
        "    ax.set_ylabel('Silhouette Score', fontsize=12)\n",
        "    ax.set_title('Silhouette Score Comparison (higher is better)', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylim([0, max(1, valid_data['Silhouette_Score'].max() * 1.1)])\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    for i, (idx, row) in enumerate(valid_data.iterrows()):\n",
        "        ax.text(i, row['Silhouette_Score'] + 0.01, f\"{row['Silhouette_Score']:.3f}\", \n",
        "               ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Davies-Bouldin Score\n",
        "ax = axes[0, 1]\n",
        "valid_data = evaluation_df[evaluation_df['Davies_Bouldin'] < np.inf]\n",
        "if len(valid_data) > 0:\n",
        "    bars = ax.bar(valid_data['Method'], valid_data['Davies_Bouldin'],\n",
        "                  color=['steelblue', 'coral', 'mediumseagreen'][:len(valid_data)])\n",
        "    ax.set_ylabel('Davies-Bouldin Score', fontsize=12)\n",
        "    ax.set_title('Davies-Bouldin Score Comparison (lower is better)', fontsize=14, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    for i, (idx, row) in enumerate(valid_data.iterrows()):\n",
        "        ax.text(i, row['Davies_Bouldin'] + 0.05, f\"{row['Davies_Bouldin']:.3f}\", \n",
        "               ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Calinski-Harabasz Score\n",
        "ax = axes[1, 0]\n",
        "valid_data = evaluation_df[evaluation_df['Calinski_Harabasz'] > 0]\n",
        "if len(valid_data) > 0:\n",
        "    bars = ax.bar(valid_data['Method'], valid_data['Calinski_Harabasz'],\n",
        "                  color=['steelblue', 'coral', 'mediumseagreen'][:len(valid_data)])\n",
        "    ax.set_ylabel('Calinski-Harabasz Score', fontsize=12)\n",
        "    ax.set_title('Calinski-Harabasz Score Comparison (higher is better)', fontsize=14, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    for i, (idx, row) in enumerate(valid_data.iterrows()):\n",
        "        ax.text(i, row['Calinski_Harabasz'] + row['Calinski_Harabasz']*0.02, \n",
        "               f\"{row['Calinski_Harabasz']:.0f}\", ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Number of Clusters\n",
        "ax = axes[1, 1]\n",
        "bars = ax.bar(evaluation_df['Method'], evaluation_df['N_Clusters'],\n",
        "             color=['steelblue', 'coral', 'mediumseagreen'][:len(evaluation_df)])\n",
        "ax.set_ylabel('Number of Clusters', fontsize=12)\n",
        "ax.set_title('Number of Clusters', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "for i, (idx, row) in enumerate(evaluation_df.iterrows()):\n",
        "    ax.text(i, row['N_Clusters'] + 0.1, f\"{int(row['N_Clusters'])}\", \n",
        "           ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / '2.4_metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Cluster Agreement Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute Adjusted Rand Index (ARI) between different methods\n",
        "if labels_kmeans is not None and labels_hierarchical is not None:\n",
        "    ari_kmeans_hierarchical = adjusted_rand_score(labels_kmeans, labels_hierarchical)\n",
        "    print(f\"Adjusted Rand Index (K-means vs Hierarchical): {ari_kmeans_hierarchical:.4f}\")\n",
        "\n",
        "if labels_kmeans is not None and labels_dbscan is not None:\n",
        "    # For DBSCAN, compare only non-noise points\n",
        "    non_noise_mask = labels_dbscan != -1\n",
        "    if np.sum(non_noise_mask) > 0:\n",
        "        ari_kmeans_dbscan = adjusted_rand_score(\n",
        "            labels_kmeans[non_noise_mask], \n",
        "            labels_dbscan[non_noise_mask]\n",
        "        )\n",
        "        print(f\"Adjusted Rand Index (K-means vs DBSCAN, non-noise only): {ari_kmeans_dbscan:.4f}\")\n",
        "\n",
        "if labels_hierarchical is not None and labels_dbscan is not None:\n",
        "    non_noise_mask = labels_dbscan != -1\n",
        "    if np.sum(non_noise_mask) > 0:\n",
        "        ari_hierarchical_dbscan = adjusted_rand_score(\n",
        "            labels_hierarchical[non_noise_mask],\n",
        "            labels_dbscan[non_noise_mask]\n",
        "        )\n",
        "        print(f\"Adjusted Rand Index (Hierarchical vs DBSCAN, non-noise only): {ari_hierarchical_dbscan:.4f}\")\n",
        "\n",
        "# Create agreement matrix\n",
        "agreement_data = []\n",
        "if labels_kmeans is not None and labels_hierarchical is not None:\n",
        "    agreement_data.append(['K-means', 'Hierarchical', adjusted_rand_score(labels_kmeans, labels_hierarchical)])\n",
        "if labels_kmeans is not None and labels_dbscan is not None:\n",
        "    non_noise_mask = labels_dbscan != -1\n",
        "    if np.sum(non_noise_mask) > 0:\n",
        "        agreement_data.append(['K-means', 'DBSCAN', adjusted_rand_score(labels_kmeans[non_noise_mask], labels_dbscan[non_noise_mask])])\n",
        "if labels_hierarchical is not None and labels_dbscan is not None:\n",
        "    non_noise_mask = labels_dbscan != -1\n",
        "    if np.sum(non_noise_mask) > 0:\n",
        "        agreement_data.append(['Hierarchical', 'DBSCAN', adjusted_rand_score(labels_hierarchical[non_noise_mask], labels_dbscan[non_noise_mask])])\n",
        "\n",
        "if agreement_data:\n",
        "    agreement_df = pd.DataFrame(agreement_data, columns=['Method 1', 'Method 2', 'ARI'])\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CLUSTER AGREEMENT (Adjusted Rand Index)\")\n",
        "    print(\"=\"*80)\n",
        "    print(agreement_df.to_string(index=False))\n",
        "    print(\"\\nNote: ARI ranges from -1 to 1, where 1 indicates perfect agreement\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visual Comparison of Clustering Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reduce to 2D using PCA for visualization\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Create side-by-side comparison\n",
        "n_methods = sum([1 for labels in methods.values() if labels is not None])\n",
        "fig, axes = plt.subplots(1, n_methods, figsize=(6*n_methods, 6))\n",
        "\n",
        "plot_idx = 0\n",
        "for method_name, labels in methods.items():\n",
        "    if labels is not None:\n",
        "        ax = axes[plot_idx] if n_methods > 1 else axes\n",
        "        \n",
        "        # Plot clusters\n",
        "        if -1 in labels:\n",
        "            # DBSCAN: handle noise points\n",
        "            for cluster_id in sorted(np.unique(labels)):\n",
        "                mask = labels == cluster_id\n",
        "                if cluster_id == -1:\n",
        "                    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
        "                             c='red', marker='x', s=20, alpha=0.5, label='Noise', linewidths=1)\n",
        "                else:\n",
        "                    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
        "                             label=f'Cluster {cluster_id}', alpha=0.6, s=30, edgecolors='k', linewidth=0.3)\n",
        "        else:\n",
        "            # K-means and Hierarchical\n",
        "            scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, \n",
        "                               cmap='viridis', alpha=0.6, s=30, edgecolors='k', linewidth=0.3)\n",
        "            plt.colorbar(scatter, ax=ax, label='Cluster')\n",
        "        \n",
        "        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})', fontsize=11)\n",
        "        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})', fontsize=11)\n",
        "        ax.set_title(f'{method_name}', fontsize=14, fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        if -1 in labels:\n",
        "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "        \n",
        "        plot_idx += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(plots_dir / '2.4_clustering_visual_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Method Comparison: Advantages and Disadvantages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comparison_table = pd.DataFrame({\n",
        "    'Method': ['K-means', 'DBSCAN', 'Hierarchical'],\n",
        "    'Advantages': [\n",
        "        'Fast and scalable; Works well with spherical clusters; Simple to implement',\n",
        "        'Finds clusters of arbitrary shape; Identifies noise/outliers; No need to specify k',\n",
        "        'Provides hierarchical structure; No need to specify k; Interpretable dendrograms'\n",
        "    ],\n",
        "    'Disadvantages': [\n",
        "        'Assumes spherical clusters; Requires k a priori; Sensitive to initialization',\n",
        "        'Sensitive to parameters (eps, min_samples); Struggles with varying densities',\n",
        "        'Computationally expensive; Sensitive to noise; Different linkage methods give different results'\n",
        "    ],\n",
        "    'Best For': [\n",
        "        'Well-separated, spherical clusters; Large datasets',\n",
        "        'Clusters of arbitrary shape; Outlier detection; Unknown number of clusters',\n",
        "        'Small to medium datasets; Need for hierarchical structure; Interpretability'\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"METHOD COMPARISON: ADVANTAGES AND DISADVANTAGES\")\n",
        "print(\"=\"*80)\n",
        "for idx, row in comparison_table.iterrows():\n",
        "    print(f\"\\n{row['Method']}:\")\n",
        "    print(f\"  Advantages: {row['Advantages']}\")\n",
        "    print(f\"  Disadvantages: {row['Disadvantages']}\")\n",
        "    print(f\"  Best For: {row['Best For']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Final Recommendations and Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Determine best method based on metrics\n",
        "if len(evaluation_df) > 0:\n",
        "    # Normalize scores for comparison (higher is better for all after normalization)\n",
        "    eval_normalized = evaluation_df.copy()\n",
        "    \n",
        "    # Silhouette: already in [-1, 1], higher is better\n",
        "    eval_normalized['Silhouette_Norm'] = eval_normalized['Silhouette_Score']\n",
        "    \n",
        "    # Davies-Bouldin: lower is better, so invert\n",
        "    max_db = eval_normalized[eval_normalized['Davies_Bouldin'] < np.inf]['Davies_Bouldin'].max()\n",
        "    eval_normalized['DB_Norm'] = 1 - (eval_normalized['Davies_Bouldin'] / max_db)\n",
        "    eval_normalized.loc[eval_normalized['Davies_Bouldin'] == np.inf, 'DB_Norm'] = 0\n",
        "    \n",
        "    # Calinski-Harabasz: higher is better, normalize\n",
        "    max_ch = eval_normalized['Calinski_Harabasz'].max()\n",
        "    eval_normalized['CH_Norm'] = eval_normalized['Calinski_Harabasz'] / max_ch\n",
        "    \n",
        "    # Combined score (weighted average)\n",
        "    eval_normalized['Combined_Score'] = (\n",
        "        0.4 * eval_normalized['Silhouette_Norm'] +\n",
        "        0.3 * eval_normalized['DB_Norm'] +\n",
        "        0.3 * eval_normalized['CH_Norm']\n",
        "    )\n",
        "    \n",
        "    best_method = eval_normalized.loc[eval_normalized['Combined_Score'].idxmax(), 'Method']\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "    print(\"FINAL RECOMMENDATION\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nBased on comprehensive evaluation metrics, the best clustering method is:\")\n",
        "    print(f\"  → {best_method}\")\n",
        "    print(f\"\\nCombined Score: {eval_normalized.loc[eval_normalized['Method'] == best_method, 'Combined_Score'].values[0]:.4f}\")\n",
        "    print(f\"\\nDetailed metrics for {best_method}:\")\n",
        "    best_row = evaluation_df[evaluation_df['Method'] == best_method].iloc[0]\n",
        "    print(f\"  - Number of clusters: {int(best_row['N_Clusters'])}\")\n",
        "    if best_row['N_Noise'] > 0:\n",
        "        print(f\"  - Noise points: {int(best_row['N_Noise'])} ({best_row['Noise_Ratio']:.1%})\")\n",
        "    print(f\"  - Silhouette Score: {best_row['Silhouette_Score']:.4f}\")\n",
        "    print(f\"  - Davies-Bouldin Score: {best_row['Davies_Bouldin']:.4f}\")\n",
        "    print(f\"  - Calinski-Harabasz Score: {best_row['Calinski_Harabasz']:.4f}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ALL METHODS RANKED BY COMBINED SCORE\")\n",
        "    print(\"=\"*80)\n",
        "    ranked = eval_normalized.sort_values('Combined_Score', ascending=False)[['Method', 'Combined_Score', 'Silhouette_Score', 'Davies_Bouldin', 'Calinski_Harabasz']]\n",
        "    print(ranked.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Key Findings:\n",
        "1. **Performance Comparison**: All three methods evaluated using multiple metrics\n",
        "2. **Cluster Agreement**: Analyzed similarity between different clustering results\n",
        "3. **Visual Comparison**: Side-by-side visualization of clustering results\n",
        "4. **Best Method**: Identified optimal clustering approach for the dataset\n",
        "\n",
        "### Recommendations:\n",
        "- Use the selected best method for final patient profiling\n",
        "- Consider domain knowledge when interpreting clusters\n",
        "- Document cluster characteristics for each method\n",
        "- Consider ensemble approaches if methods show high agreement\n",
        "\n",
        "### Next Steps:\n",
        "- Use selected clustering for patient segmentation\n",
        "- Analyze clinical significance of identified clusters\n",
        "- Proceed to time series analysis (Task 3)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
