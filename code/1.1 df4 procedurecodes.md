```python
%matplotlib inline
import math
import re
import numpy as np
import pandas as pd
import scipy.stats as stats
import matplotlib.pyplot as plt
import matplotlib.pyplot as plt
import seaborn as sns
import re

from collections import defaultdict
from scipy.stats import pearsonr
import pandas as pd
from IPython.display import display

```


```python
#%pip install matplotlib-venn
```


```python
DATA_DIR = r"Y:\Studium\3. Sem UniPI\Data Analytics 4 digital Health\Data"

DATASETS = {
    "heart_diagnoses_1": "heart_diagnoses_1.csv",
    "laboratory_events_codes_2": "laboratory_events_codes_2.csv",
    "microbiology_events_codes_3": "microbiology_events_codes_3.csv",
    "procedure_code_4": "procedure_code_4.csv",
}
name = "procedure_code_4"
```


```python
df = pd.read_csv(f"{DATA_DIR}/{DATASETS[name]}", index_col=False)

df.columns
```




    Index(['subject_id', 'hadm_id', 'seq_num', 'chartdate', 'icd_code',
           'long_title'],
          dtype='object')




```python
df[['subject_id','hadm_id']].duplicated().any()
```




    np.True_



# INspections

## A


```python
df.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>subject_id</th>
      <th>hadm_id</th>
      <th>seq_num</th>
      <th>chartdate</th>
      <th>icd_code</th>
      <th>long_title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10000980</td>
      <td>26913865</td>
      <td>1</td>
      <td>2189-07-01 03:00:00</td>
      <td>0066</td>
      <td>Percutaneous transluminal coronary angioplasty...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10000980</td>
      <td>26913865</td>
      <td>2</td>
      <td>2189-07-01 03:00:00</td>
      <td>3607</td>
      <td>Insertion of drug-eluting coronary artery sten...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10000980</td>
      <td>26913865</td>
      <td>3</td>
      <td>2189-07-01 03:00:00</td>
      <td>0045</td>
      <td>Insertion of one vascular stent</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10000980</td>
      <td>26913865</td>
      <td>4</td>
      <td>2189-07-01 03:00:00</td>
      <td>0041</td>
      <td>Procedure on two vessels</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10000980</td>
      <td>26913865</td>
      <td>5</td>
      <td>2189-07-01 03:00:00</td>
      <td>3722</td>
      <td>Left heart cardiac catheterization</td>
    </tr>
    <tr>
      <th>5</th>
      <td>10000980</td>
      <td>26913865</td>
      <td>6</td>
      <td>2189-07-01 03:00:00</td>
      <td>8856</td>
      <td>Coronary arteriography using two catheters</td>
    </tr>
    <tr>
      <th>6</th>
      <td>10000980</td>
      <td>26913865</td>
      <td>7</td>
      <td>2189-07-01 03:00:00</td>
      <td>0044</td>
      <td>Procedure on vessel bifurcation</td>
    </tr>
    <tr>
      <th>7</th>
      <td>10002013</td>
      <td>24760295</td>
      <td>1</td>
      <td>2160-07-12 03:00:00</td>
      <td>3722</td>
      <td>Left heart cardiac catheterization</td>
    </tr>
    <tr>
      <th>8</th>
      <td>10002013</td>
      <td>24760295</td>
      <td>2</td>
      <td>2160-07-12 03:00:00</td>
      <td>8856</td>
      <td>Coronary arteriography using two catheters</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10002155</td>
      <td>23822395</td>
      <td>1</td>
      <td>2129-08-05 03:00:00</td>
      <td>0066</td>
      <td>Percutaneous transluminal coronary angioplasty...</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.tail(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>subject_id</th>
      <th>hadm_id</th>
      <th>seq_num</th>
      <th>chartdate</th>
      <th>icd_code</th>
      <th>long_title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14487</th>
      <td>19997293</td>
      <td>28847872</td>
      <td>3</td>
      <td>2123-12-30 03:00:00</td>
      <td>9671</td>
      <td>Continuous invasive mechanical ventilation for...</td>
    </tr>
    <tr>
      <th>14488</th>
      <td>19997293</td>
      <td>28847872</td>
      <td>4</td>
      <td>2123-12-30 03:00:00</td>
      <td>3778</td>
      <td>Insertion of temporary transvenous pacemaker s...</td>
    </tr>
    <tr>
      <th>14489</th>
      <td>19997293</td>
      <td>28847872</td>
      <td>5</td>
      <td>2124-01-03 03:00:00</td>
      <td>8628</td>
      <td>Nonexcisional debridement of wound, infection ...</td>
    </tr>
    <tr>
      <th>14490</th>
      <td>19997293</td>
      <td>28847872</td>
      <td>6</td>
      <td>2124-01-01 03:00:00</td>
      <td>3897</td>
      <td>Central venous catheter placement with guidance</td>
    </tr>
    <tr>
      <th>14491</th>
      <td>19997367</td>
      <td>24169669</td>
      <td>1</td>
      <td>2128-02-26 03:00:00</td>
      <td>3723</td>
      <td>Combined right and left heart cardiac catheter...</td>
    </tr>
    <tr>
      <th>14492</th>
      <td>19998497</td>
      <td>21557581</td>
      <td>1</td>
      <td>2145-07-29 03:00:00</td>
      <td>0066</td>
      <td>Percutaneous transluminal coronary angioplasty...</td>
    </tr>
    <tr>
      <th>14493</th>
      <td>19998497</td>
      <td>21557581</td>
      <td>2</td>
      <td>2145-07-29 03:00:00</td>
      <td>3607</td>
      <td>Insertion of drug-eluting coronary artery sten...</td>
    </tr>
    <tr>
      <th>14494</th>
      <td>19998497</td>
      <td>21557581</td>
      <td>3</td>
      <td>2145-07-29 03:00:00</td>
      <td>0045</td>
      <td>Insertion of one vascular stent</td>
    </tr>
    <tr>
      <th>14495</th>
      <td>19998497</td>
      <td>21557581</td>
      <td>4</td>
      <td>2145-07-29 03:00:00</td>
      <td>0040</td>
      <td>Procedure on single vessel</td>
    </tr>
    <tr>
      <th>14496</th>
      <td>19998497</td>
      <td>21557581</td>
      <td>5</td>
      <td>2145-07-29 03:00:00</td>
      <td>8856</td>
      <td>Coronary arteriography using two catheters</td>
    </tr>
  </tbody>
</table>
</div>



## B


```python
df["icd_code"].value_counts(dropna=False) 
```




    icd_code
    8856       1603
    0066       1020
    3722        975
    0040        848
    3607        685
               ... 
    3814          1
    0CQ5XZZ       1
    047H3DZ       1
    0B9P30Z       1
    0DH63UZ       1
    Name: count, Length: 633, dtype: int64




```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 14497 entries, 0 to 14496
    Data columns (total 6 columns):
     #   Column      Non-Null Count  Dtype 
    ---  ------      --------------  ----- 
     0   subject_id  14497 non-null  int64 
     1   hadm_id     14497 non-null  int64 
     2   seq_num     14497 non-null  int64 
     3   chartdate   14497 non-null  object
     4   icd_code    14497 non-null  object
     5   long_title  14497 non-null  object
    dtypes: int64(3), object(3)
    memory usage: 679.7+ KB
    

yay no none

# Data Understanding and Preprocessing, cleaning 


```python
df.duplicated().sum()
```




    np.int64(0)




```python
#show duplicated rows
df[df.duplicated(keep=False)].sort_values(by=df.columns.tolist()).head(20)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>subject_id</th>
      <th>hadm_id</th>
      <th>seq_num</th>
      <th>chartdate</th>
      <th>icd_code</th>
      <th>long_title</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>




```python
df = df.drop_duplicates()
```


```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 14497 entries, 0 to 14496
    Data columns (total 6 columns):
     #   Column      Non-Null Count  Dtype 
    ---  ------      --------------  ----- 
     0   subject_id  14497 non-null  int64 
     1   hadm_id     14497 non-null  int64 
     2   seq_num     14497 non-null  int64 
     3   chartdate   14497 non-null  object
     4   icd_code    14497 non-null  object
     5   long_title  14497 non-null  object
    dtypes: int64(3), object(3)
    memory usage: 679.7+ KB
    


```python
for col in df.columns:
    if col == 'charttime' or col == 'hadm_id' or col == 'subject_id' or col == 'chartdate':
        continue
    print(f"{col}: {df[col].value_counts().tail(30)}")
```

    seq_num: seq_num
    1     3459
    2     2862
    3     2141
    4     1676
    5     1390
    6     1095
    7      694
    8      395
    9      221
    10     153
    11     110
    12      83
    13      54
    14      38
    15      27
    16      24
    17      17
    18      13
    19      12
    20       9
    21       8
    22       5
    23       4
    24       3
    25       1
    26       1
    27       1
    28       1
    Name: count, dtype: int64
    icd_code: icd_code
    0W9D3ZZ    1
    8674       1
    0WCD0ZZ    1
    5A1522F    1
    02703EZ    1
    03743D6    1
    3729       1
    3869       1
    9952       1
    02580ZZ    1
    02L74CK    1
    5A15223    1
    0B978ZZ    1
    0DH58DZ    1
    0KCH0ZZ    1
    3E1F88Z    1
    0JH63XZ    1
    5A09357    1
    7902       1
    7903       1
    543        1
    7747       1
    7867       1
    02703Z6    1
    0060       1
    3814       1
    0CQ5XZZ    1
    047H3DZ    1
    0B9P30Z    1
    0DH63UZ    1
    Name: count, dtype: int64
    long_title: long_title
    Drainage of Pericardial Cavity, Percutaneous Approach                                                            1
    Attachment of pedicle or flap graft to other sites                                                               1
    Extirpation of Matter from Pericardial Cavity, Open Approach                                                     1
    Extracorporeal Oxygenation, Membrane, Central                                                                    1
    Dilation of Coronary Artery, One Artery with Two Intraluminal Devices, Percutaneous Approach                     1
    Dilation of Left Subclavian Artery, Bifurcation, with Intraluminal Device, Percutaneous Approach                 1
    Other diagnostic procedures on heart and pericardium                                                             1
    Other excision of vessels, lower limb veins                                                                      1
    Prophylactic vaccination against influenza                                                                       1
    Destruction of Conduction Mechanism, Open Approach                                                               1
    Occlusion of Left Atrial Appendage with Extraluminal Device, Percutaneous Endoscopic Approach                    1
    Extracorporeal Membrane Oxygenation, Continuous                                                                  1
    Drainage of Left Main Bronchus, Via Natural or Artificial Opening Endoscopic                                     1
    Insertion of Intraluminal Device into Esophagus, Via Natural or Artificial Opening Endoscopic                    1
    Extirpation of Matter from Right Thorax Muscle, Open Approach                                                    1
    Irrigation of Respiratory Tract using Irrigating Substance, Via Natural or Artificial Opening Endoscopic         1
    Insertion of Tunneled Vascular Access Device into Chest Subcutaneous Tissue and Fascia, Percutaneous Approach    1
    Assistance with Respiratory Ventilation, Less than 24 Consecutive Hours, Continuous Positive Airway Pressure     1
    Closed reduction of fracture without internal fixation, radius and ulna                                          1
    Closed reduction of fracture without internal fixation, carpals and metacarpals                                  1
    Excision or destruction of lesion or tissue of abdominal wall or umbilicus                                       1
    Biopsy of bone, tibia and fibula                                                                                 1
    Removal of implanted devices from bone, tibia and fibula                                                         1
    Dilation of Coronary Artery, One Artery, Bifurcation, Percutaneous Approach                                      1
    Insertion of drug-eluting stent(s) of superficial femoral artery                                                 1
    Endarterectomy, aorta                                                                                            1
    Repair Upper Gingiva, External Approach                                                                          1
    Dilation of Right External Iliac Artery with Intraluminal Device, Percutaneous Approach                          1
    Drainage of Left Pleura with Drainage Device, Percutaneous Approach                                              1
    Insertion of Feeding Device into Stomach, Percutaneous Approach                                                  1
    Name: count, dtype: int64
    

## Check for wrong NaNs / non typical entries in each column

#### Find wrong NaNs


```python
# find any one or two character or ___ etc in icd_code 
# Find suspicious/invalid icd_code entries (short codes, underscores, special chars)
print("="*60)
print("CHECKING icd_code FOR INVALID ENTRIES")
print("="*60)

# 1. Very short codes (1-2 characters)
short_codes = df[df['icd_code'].str.len() <= 2]
print(f"\nCodes with 1-2 characters: {len(short_codes)}")
if len(short_codes) > 0:
    print(short_codes['icd_code'].value_counts())

# 2. Codes containing underscores or special patterns
underscore_codes = df[df['icd_code'].str.contains(r'_+', na=False)]
print(f"\nCodes with underscores: {len(underscore_codes)}")
if len(underscore_codes) > 0:
    print(underscore_codes['icd_code'].value_counts())

# 3. Non-alphanumeric codes (excluding valid ICD separators like '.')
invalid_pattern = df[df['icd_code'].str.contains(r'[^A-Za-z0-9\.]', na=False)]
print(f"\nCodes with special characters: {len(invalid_pattern)}")
if len(invalid_pattern) > 0:
    print(invalid_pattern['icd_code'].value_counts().head(20))

# 4. Empty or whitespace-only
empty_codes = df[df['icd_code'].str.strip() == '']
print(f"\nEmpty/whitespace codes: {len(empty_codes)}")

# 5. Summary of code length distribution
print(f"\n{'='*60}")
print("ICD_CODE LENGTH DISTRIBUTION")
print("="*60)
print(df['icd_code'].str.len().value_counts().sort_index())
```

    ============================================================
    CHECKING icd_code FOR INVALID ENTRIES
    ============================================================
    
    Codes with 1-2 characters: 0
    
    Codes with underscores: 0
    
    Codes with special characters: 0
    
    Empty/whitespace codes: 0
    
    ============================================================
    ICD_CODE LENGTH DISTRIBUTION
    ============================================================
    icd_code
    3      116
    4    11668
    7     2713
    Name: count, dtype: int64
    

 ## Convert datetimes


```python
cols = ['chartdate']  

for col in cols:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors='coerce')
        print(f"{col}: parsed {df[col].notna().sum()} values, {df[col].isna().sum()} NaT")

display(df[[c for c in df.columns if c in cols]])
```

    chartdate: parsed 14497 values, 0 NaT
    


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>chartdate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2189-07-01 03:00:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2189-07-01 03:00:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2189-07-01 03:00:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2189-07-01 03:00:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2189-07-01 03:00:00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>14492</th>
      <td>2145-07-29 03:00:00</td>
    </tr>
    <tr>
      <th>14493</th>
      <td>2145-07-29 03:00:00</td>
    </tr>
    <tr>
      <th>14494</th>
      <td>2145-07-29 03:00:00</td>
    </tr>
    <tr>
      <th>14495</th>
      <td>2145-07-29 03:00:00</td>
    </tr>
    <tr>
      <th>14496</th>
      <td>2145-07-29 03:00:00</td>
    </tr>
  </tbody>
</table>
<p>14497 rows × 1 columns</p>
</div>


## Little intermed inspection 


```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 14497 entries, 0 to 14496
    Data columns (total 6 columns):
     #   Column      Non-Null Count  Dtype         
    ---  ------      --------------  -----         
     0   subject_id  14497 non-null  int64         
     1   hadm_id     14497 non-null  int64         
     2   seq_num     14497 non-null  int64         
     3   chartdate   14497 non-null  datetime64[ns]
     4   icd_code    14497 non-null  object        
     5   long_title  14497 non-null  object        
    dtypes: datetime64[ns](1), int64(3), object(2)
    memory usage: 679.7+ KB
    

## Handle missing values


```python
# print sum of all missing values per column
for col in df.columns:
    missing_count = df[col].isna().sum()
    if missing_count > 0:
        print(f"Column '{col}': {missing_count} missing values")
```

## Save


```python
df.to_csv(f"{DATA_DIR}/{DATASETS[name].replace('.csv', '_cleaned.csv')}", index=False)
```


```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 14497 entries, 0 to 14496
    Data columns (total 6 columns):
     #   Column      Non-Null Count  Dtype         
    ---  ------      --------------  -----         
     0   subject_id  14497 non-null  int64         
     1   hadm_id     14497 non-null  int64         
     2   seq_num     14497 non-null  int64         
     3   chartdate   14497 non-null  datetime64[ns]
     4   icd_code    14497 non-null  object        
     5   long_title  14497 non-null  object        
    dtypes: datetime64[ns](1), int64(3), object(2)
    memory usage: 679.7+ KB
    

# Task 1.2: Create features and slim version


```python
# load already cleaned to skip first steps
df = pd.read_csv(f"{DATA_DIR}/{DATASETS[name].replace('.csv', '_cleaned.csv')}")

cols = ['charttime', 'chartdate']  

for col in cols:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors='coerce')
        print(f"{col}: parsed {df[col].notna().sum()} values, {df[col].isna().sum()} NaT")
```

    chartdate: parsed 14497 values, 0 NaT
    


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>chartdate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2189-07-01 03:00:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2189-07-01 03:00:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2189-07-01 03:00:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2189-07-01 03:00:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2189-07-01 03:00:00</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>14492</th>
      <td>2145-07-29 03:00:00</td>
    </tr>
    <tr>
      <th>14493</th>
      <td>2145-07-29 03:00:00</td>
    </tr>
    <tr>
      <th>14494</th>
      <td>2145-07-29 03:00:00</td>
    </tr>
    <tr>
      <th>14495</th>
      <td>2145-07-29 03:00:00</td>
    </tr>
    <tr>
      <th>14496</th>
      <td>2145-07-29 03:00:00</td>
    </tr>
  </tbody>
</table>
<p>14497 rows × 1 columns</p>
</div>



```python
df_slim = df.copy()
```


```python
df_slim.columns
```




    Index(['subject_id', 'hadm_id', 'seq_num', 'chartdate', 'icd_code',
           'long_title'],
          dtype='object')




```python
df_slim.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 14497 entries, 0 to 14496
    Data columns (total 6 columns):
     #   Column      Non-Null Count  Dtype         
    ---  ------      --------------  -----         
     0   subject_id  14497 non-null  int64         
     1   hadm_id     14497 non-null  int64         
     2   seq_num     14497 non-null  int64         
     3   chartdate   14497 non-null  datetime64[ns]
     4   icd_code    14497 non-null  object        
     5   long_title  14497 non-null  object        
    dtypes: datetime64[ns](1), int64(3), object(2)
    memory usage: 679.7+ KB
    


```python
df_slim["chartdate"] = pd.to_datetime(df_slim["chartdate"], errors='coerce')
```

## Features


```python
df_slim = df_slim.sort_values(['subject_id', 'hadm_id', 'chartdate'])
gb = df_slim.groupby(['subject_id', 'hadm_id'])

def first_non_null(series):
    """Get first non-null value, or None if all null"""
    non_null = series.dropna()
    return non_null.iloc[0] if len(non_null) > 0 else None
```


```python
# Total count of procedures
feat_total_proc = gb.size().rename('total_procedures')

# Unique codes and titles
feat_unique_icd = gb['icd_code'].nunique().rename('unique_icd_codes')
feat_unique_titles = gb['long_title'].nunique().rename('unique_titles')

# Temporal span in days
feat_proc_span = (
    (gb['chartdate'].max() - gb['chartdate'].min()).dt.total_seconds() / (60*60*24)
).rename('procedure_span_days')

# Merge all features
procedure_features = pd.concat([
    feat_total_proc,
    feat_unique_icd,
    feat_unique_titles,
    feat_proc_span
], axis=1)

# Presence flag
procedure_features['has_procedure'] = 1

procedure_features = procedure_features.reset_index()

```


```python
procedure_features.to_csv(f"{DATA_DIR}/{DATASETS[name].replace('.csv', '_agg_features_large.csv')}", index=False)
```

### Corr


```python
print("="*80)
print("CORRELATION MATRIX ANALYSIS")
print("="*80)

# Select numeric columns only
numeric_cols = procedure_features.select_dtypes(include=[np.number]).columns.tolist()
print(f"\nNumeric columns found: {numeric_cols}")
print(f"Total numeric columns: {len(numeric_cols)}\n")

if len(numeric_cols) > 1:
    # Calculate correlation matrix
    correlation_matrix = procedure_features[numeric_cols].corr()
    
    print("="*80)
    print("CORRELATION MATRIX")
    print("="*80)
    print(correlation_matrix.round(3))
    
    # Create visualization
    fig, axes = plt.subplots(1, 2, figsize=(18, 8))
    
    # Plot 1: Full correlation heatmap
    ax1 = axes[0]
    sns.heatmap(correlation_matrix, 
                annot=True, 
                fmt='.2f', 
                cmap='coolwarm', 
                center=0,
                square=True,
                linewidths=0.5,
                cbar_kws={'label': 'Correlation Coefficient'},
                ax=ax1)
    ax1.set_title('Full Correlation Matrix Heatmap', fontsize=14, fontweight='bold')
    plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')
    plt.setp(ax1.get_yticklabels(), rotation=0)
    
    # Plot 2: Mask for upper triangle (cleaner view)
    ax2 = axes[1]
    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
    sns.heatmap(correlation_matrix, 
                annot=True, 
                fmt='.2f', 
                cmap='coolwarm', 
                center=0,
                square=True,
                linewidths=0.5,
                mask=mask,
                cbar_kws={'label': 'Correlation Coefficient'},
                ax=ax2)
    ax2.set_title('Lower Triangle Correlation Matrix (Unique Pairs)', fontsize=14, fontweight='bold')
    plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')
    plt.setp(ax2.get_yticklabels(), rotation=0)
    
    plt.tight_layout()
    plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Extract strong correlations (> 0.5 or < -0.5, excluding diagonal)
    print("\n" + "="*80)
    print("STRONG CORRELATIONS (|r| > 0.5, excluding self-correlations)")
    print("="*80)
    
    strong_corr = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i+1, len(correlation_matrix.columns)):
            corr_value = correlation_matrix.iloc[i, j]
            if abs(corr_value) > 0.5:
                strong_corr.append({
                    'Variable 1': correlation_matrix.columns[i],
                    'Variable 2': correlation_matrix.columns[j],
                    'Correlation': corr_value,
                    'Strength': 'Strong Positive' if corr_value > 0 else 'Strong Negative'
                })
    
    if strong_corr:
        strong_corr_df = pd.DataFrame(strong_corr).sort_values('Correlation', key=abs, ascending=False)
        print(f"\nFound {len(strong_corr)} strong correlations:\n")
        print(strong_corr_df.to_string(index=False))
    else:
        print("\nNo correlations with |r| > 0.5 found")
    
    # Moderate correlations (0.3 to 0.5)
    print("\n" + "="*80)
    print("MODERATE CORRELATIONS (0.3 < |r| ≤ 0.5)")
    print("="*80)
    
    moderate_corr = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i+1, len(correlation_matrix.columns)):
            corr_value = correlation_matrix.iloc[i, j]
            if 0.3 < abs(corr_value) <= 0.5:
                moderate_corr.append({
                    'Variable 1': correlation_matrix.columns[i],
                    'Variable 2': correlation_matrix.columns[j],
                    'Correlation': corr_value,
                    'Strength': 'Moderate Positive' if corr_value > 0 else 'Moderate Negative'
                })
    
    if moderate_corr:
        moderate_corr_df = pd.DataFrame(moderate_corr).sort_values('Correlation', key=abs, ascending=False)
        print(f"\nFound {len(moderate_corr)} moderate correlations:\n")
        print(moderate_corr_df.to_string(index=False))
    else:
        print("\nNo moderate correlations found (0.3 < |r| ≤ 0.5)")
    
    # Summary statistics
    print("\n" + "="*80)
    print("SUMMARY STATISTICS")
    print("="*80)
    
    # Get correlation values (excluding diagonal)
    corr_values = []
    for i in range(len(correlation_matrix.columns)):
        for j in range(i+1, len(correlation_matrix.columns)):
            corr_values.append(correlation_matrix.iloc[i, j])
    
    corr_values = np.array(corr_values)
    print(f"\nMean correlation: {corr_values.mean():.3f}")
    print(f"Median correlation: {np.median(corr_values):.3f}")
    print(f"Std Dev: {corr_values.std():.3f}")
    print(f"Min: {corr_values.min():.3f}")
    print(f"Max: {corr_values.max():.3f}")
    
    # Distribution of correlations
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.hist(corr_values, bins=30, edgecolor='black', alpha=0.7, color='steelblue')
    ax.axvline(corr_values.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {corr_values.mean():.3f}')
    ax.axvline(np.median(corr_values), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(corr_values):.3f}')
    ax.set_xlabel('Correlation Coefficient', fontsize=12, fontweight='bold')
    ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')
    ax.set_title('Distribution of Correlation Coefficients', fontsize=13, fontweight='bold')
    ax.legend(fontsize=11)
    ax.grid(alpha=0.3, linestyle='--')
    
    plt.tight_layout()
    plt.savefig('correlation_distribution.png', dpi=300, bbox_inches='tight')
    plt.show()
    
else:
    print("⚠️ Not enough numeric columns for correlation analysis")
    print(f"Found only {len(numeric_cols)} numeric column(s)")
```

    ================================================================================
    CORRELATION MATRIX ANALYSIS
    ================================================================================
    
    Numeric columns found: ['subject_id', 'hadm_id', 'total_procedures', 'unique_icd_codes', 'unique_titles', 'procedure_span_days', 'has_procedure']
    Total numeric columns: 7
    
    ================================================================================
    CORRELATION MATRIX
    ================================================================================
                         subject_id  hadm_id  total_procedures  unique_icd_codes  \
    subject_id                1.000   -0.020            -0.016            -0.022   
    hadm_id                  -0.020    1.000             0.016             0.010   
    total_procedures         -0.016    0.016             1.000             0.979   
    unique_icd_codes         -0.022    0.010             0.979             1.000   
    unique_titles            -0.022    0.010             0.979             1.000   
    procedure_span_days       0.000    0.026             0.454             0.418   
    has_procedure               NaN      NaN               NaN               NaN   
    
                         unique_titles  procedure_span_days  has_procedure  
    subject_id                  -0.022                0.000            NaN  
    hadm_id                      0.010                0.026            NaN  
    total_procedures             0.979                0.454            NaN  
    unique_icd_codes             1.000                0.418            NaN  
    unique_titles                1.000                0.418            NaN  
    procedure_span_days          0.418                1.000            NaN  
    has_procedure                  NaN                  NaN            NaN  
    


    
![png](1.1%20df4%20procedurecodes_files/1.1%20df4%20procedurecodes_42_1.png)
    


    
    ================================================================================
    STRONG CORRELATIONS (|r| > 0.5, excluding self-correlations)
    ================================================================================
    
    Found 3 strong correlations:
    
          Variable 1       Variable 2  Correlation        Strength
    unique_icd_codes    unique_titles     1.000000 Strong Positive
    total_procedures unique_icd_codes     0.978507 Strong Positive
    total_procedures    unique_titles     0.978507 Strong Positive
    
    ================================================================================
    MODERATE CORRELATIONS (0.3 < |r| ≤ 0.5)
    ================================================================================
    
    Found 3 moderate correlations:
    
          Variable 1          Variable 2  Correlation          Strength
    total_procedures procedure_span_days     0.454488 Moderate Positive
    unique_icd_codes procedure_span_days     0.418050 Moderate Positive
       unique_titles procedure_span_days     0.418050 Moderate Positive
    
    ================================================================================
    SUMMARY STATISTICS
    ================================================================================
    
    Mean correlation: nan
    Median correlation: nan
    Std Dev: nan
    Min: nan
    Max: nan
    


    
![png](1.1%20df4%20procedurecodes_files/1.1%20df4%20procedurecodes_42_3.png)
    



```python

```

### Dropunused


```python
procedure_features.columns
```




    Index(['subject_id', 'hadm_id', 'total_procedures', 'unique_icd_codes',
           'unique_titles', 'procedure_span_days', 'has_procedure'],
          dtype='object')




```python
procedure_features_reduced = [
    'subject_id',
    'hadm_id',
    'has_procedure',
    'total_procedures',       # overall procedure activity
    'unique_icd_codes',       # diversity of procedures
    'procedure_span_days'     # duration of procedures during admission
]
features_to_keep = [col for col in procedure_features_reduced if col in procedure_features.columns]
feat_reduced = procedure_features[features_to_keep]
```

## Save SLim


```python
feat_reduced.to_csv(f"{DATA_DIR}/{DATASETS[name].replace('.csv', '_agg_features.csv')}", index=False)
```


```python

```
