{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8aaf4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f639a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\"Y:\\Studium\\3. Sem UniPI\\Data Analytics 4 digital Health\\Data\"\n",
    "\n",
    "DATASETS = {\n",
    "    \"heart_diagnoses_1\": \"heart_diagnoses_1.csv\",\n",
    "    \"laboratory_events_codes_2\": \"laboratory_events_codes_2.csv\",\n",
    "    \"microbiology_events_codes_3\": \"microbiology_events_codes_3.csv\",\n",
    "    \"procedure_code_4\": \"procedure_code_4.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c414f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hadm_id', 'charttime', 'value', 'valuenum', 'valueuom',\n",
       "       'ref_range_lower', 'ref_range_upper', 'flag', 'label', 'fluid',\n",
       "       'examination_group', 'analysis_batch_id', 'qc_flag', 'ref_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{DATA_DIR}/{DATASETS['laboratory_events_codes_2']}\", index_col=False)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a214bba",
   "metadata": {},
   "source": [
    "# INspections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f28e781",
   "metadata": {},
   "source": [
    "## A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d2b481f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "      <th>fluid</th>\n",
       "      <th>examination_group</th>\n",
       "      <th>analysis_batch_id</th>\n",
       "      <th>qc_flag</th>\n",
       "      <th>ref_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "      <td>___</td>\n",
       "      <td>198.00</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>29.0</td>\n",
       "      <td>201.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creatine Kinase (CK)</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Cardiac Markers</td>\n",
       "      <td>BATCH_218801_N3</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "      <td>5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>ng/mL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creatine Kinase, MB Isoenzyme</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Cardiac Markers</td>\n",
       "      <td>BATCH_218801_C7</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "      <td>___</td>\n",
       "      <td>0.03</td>\n",
       "      <td>ng/mL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Troponin T</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Cardiac Markers</td>\n",
       "      <td>BATCH_218801_R4</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.10</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>INR(PT)</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Coagulation and Hemostasis</td>\n",
       "      <td>BATCH_218801_K7</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.80</td>\n",
       "      <td>sec</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.50</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>PT</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Coagulation and Hemostasis</td>\n",
       "      <td>BATCH_218801_B1</td>\n",
       "      <td>WARN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>85.8</td>\n",
       "      <td>85.80</td>\n",
       "      <td>sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>PTT</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Coagulation and Hemostasis</td>\n",
       "      <td>BATCH_218801_R1</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>___</td>\n",
       "      <td>8.10</td>\n",
       "      <td>%</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.90</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>% Hemoglobin A1c</td>\n",
       "      <td>Blood</td>\n",
       "      <td>HbA1c</td>\n",
       "      <td>BATCH_218801_O1</td>\n",
       "      <td>OK</td>\n",
       "      <td>Normal range: 70-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>___</td>\n",
       "      <td>186.00</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>91.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>eAG</td>\n",
       "      <td>Blood</td>\n",
       "      <td>HbA1c</td>\n",
       "      <td>BATCH_218801_P4</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>19</td>\n",
       "      <td>19.00</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anion Gap</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Renal Function Tests</td>\n",
       "      <td>BATCH_218801_O5</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>20</td>\n",
       "      <td>20.00</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Bicarbonate</td>\n",
       "      <td>Blood</td>\n",
       "      <td>BMP</td>\n",
       "      <td>BATCH_218801_A1</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id            charttime value  valuenum valueuom  ref_range_lower  \\\n",
       "0  29654838.0  2188-01-04 23:43:00   ___    198.00     IU/L             29.0   \n",
       "1  29654838.0  2188-01-04 23:43:00     5      5.00    ng/mL              0.0   \n",
       "2  29654838.0  2188-01-04 23:43:00   ___      0.03    ng/mL              0.0   \n",
       "3  29654838.0  2188-01-05 06:56:00   1.2      1.20      NaN              0.9   \n",
       "4  29654838.0  2188-01-05 06:56:00  12.8     12.80      sec              9.4   \n",
       "5  29654838.0  2188-01-05 06:56:00  85.8     85.80      sec             25.0   \n",
       "6  29654838.0  2188-01-05 06:56:00   ___      8.10        %              4.8   \n",
       "7  29654838.0  2188-01-05 06:56:00   ___    186.00    mg/dL             91.0   \n",
       "8  29654838.0  2188-01-05 06:56:00    19     19.00    mEq/L              8.0   \n",
       "9  29654838.0  2188-01-05 06:56:00    20     20.00    mEq/L             22.0   \n",
       "\n",
       "   ref_range_upper      flag                          label  fluid  \\\n",
       "0           201.00       NaN           Creatine Kinase (CK)  Blood   \n",
       "1            10.00       NaN  Creatine Kinase, MB Isoenzyme  Blood   \n",
       "2             0.01  abnormal                     Troponin T  Blood   \n",
       "3             1.10  abnormal                        INR(PT)  Blood   \n",
       "4            12.50  abnormal                             PT  Blood   \n",
       "5            36.50  abnormal                            PTT  Blood   \n",
       "6             5.90  abnormal               % Hemoglobin A1c  Blood   \n",
       "7           123.00  abnormal                            eAG  Blood   \n",
       "8            20.00       NaN                      Anion Gap  Blood   \n",
       "9            32.00  abnormal                    Bicarbonate  Blood   \n",
       "\n",
       "            examination_group analysis_batch_id qc_flag             ref_range  \n",
       "0             Cardiac Markers   BATCH_218801_N3      OK                   NaN  \n",
       "1             Cardiac Markers   BATCH_218801_C7      OK                   NaN  \n",
       "2             Cardiac Markers   BATCH_218801_R4      OK                   NaN  \n",
       "3  Coagulation and Hemostasis   BATCH_218801_K7      OK                   NaN  \n",
       "4  Coagulation and Hemostasis   BATCH_218801_B1    WARN                   NaN  \n",
       "5  Coagulation and Hemostasis   BATCH_218801_R1      OK                   NaN  \n",
       "6                       HbA1c   BATCH_218801_O1      OK  Normal range: 70-110  \n",
       "7                       HbA1c   BATCH_218801_P4      OK                   NaN  \n",
       "8        Renal Function Tests   BATCH_218801_O5      OK                   NaN  \n",
       "9                         BMP   BATCH_218801_A1      OK                   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8d3499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "      <th>fluid</th>\n",
       "      <th>examination_group</th>\n",
       "      <th>analysis_batch_id</th>\n",
       "      <th>qc_flag</th>\n",
       "      <th>ref_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>978493</th>\n",
       "      <td>21557581.0</td>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "      <td>29.9</td>\n",
       "      <td>29.90</td>\n",
       "      <td>%</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Hematocrit</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Complete Blood Count (CBC)</td>\n",
       "      <td>BATCH_214508_Y8</td>\n",
       "      <td>OK</td>\n",
       "      <td>Normal range: 70-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978494</th>\n",
       "      <td>21557581.0</td>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.90</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>11.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Hemoglobin</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Complete Blood Count (CBC)</td>\n",
       "      <td>BATCH_214508_D7</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978495</th>\n",
       "      <td>21557581.0</td>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "      <td>30.4</td>\n",
       "      <td>30.40</td>\n",
       "      <td>pg</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCH</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Complete Blood Count (CBC)</td>\n",
       "      <td>BATCH_214508_J8</td>\n",
       "      <td>WARN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978496</th>\n",
       "      <td>21557581.0</td>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "      <td>33.1</td>\n",
       "      <td>33.10</td>\n",
       "      <td>g/dL</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCHC</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Complete Blood Count (CBC)</td>\n",
       "      <td>BATCH_214508_O5</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978497</th>\n",
       "      <td>21557581.0</td>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "      <td>92</td>\n",
       "      <td>92.00</td>\n",
       "      <td>fL</td>\n",
       "      <td>82.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCV</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Complete Blood Count (CBC)</td>\n",
       "      <td>BATCH_214508_M3</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978498</th>\n",
       "      <td>21557581.0</td>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "      <td>180</td>\n",
       "      <td>180.00</td>\n",
       "      <td>K/uL</td>\n",
       "      <td>150.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Platelet Count</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Complete Blood Count (CBC)</td>\n",
       "      <td>BATCH_214508_B1</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978499</th>\n",
       "      <td>21557581.0</td>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.50</td>\n",
       "      <td>%</td>\n",
       "      <td>10.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDW</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Complete Blood Count (CBC)</td>\n",
       "      <td>BATCH_214508_H5</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978500</th>\n",
       "      <td>21557581.0</td>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.26</td>\n",
       "      <td>m/uL</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Red Blood Cells</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Complete Blood Count (CBC)</td>\n",
       "      <td>BATCH_214508_N7</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978501</th>\n",
       "      <td>21557581.0</td>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.40</td>\n",
       "      <td>K/uL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White Blood Cells</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Complete Blood Count (CBC)</td>\n",
       "      <td>BATCH_214508_Y6</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978502</th>\n",
       "      <td>21557581.0</td>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "      <td>47.9</td>\n",
       "      <td>47.90</td>\n",
       "      <td>fL</td>\n",
       "      <td>35.1</td>\n",
       "      <td>46.3</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>RDW-SD</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Complete Blood Count (CBC)</td>\n",
       "      <td>BATCH_214508_P9</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hadm_id            charttime value  valuenum valueuom  \\\n",
       "978493  21557581.0  2145-08-02 08:30:00  29.9     29.90        %   \n",
       "978494  21557581.0  2145-08-02 08:30:00   9.9      9.90     g/dL   \n",
       "978495  21557581.0  2145-08-02 08:30:00  30.4     30.40       pg   \n",
       "978496  21557581.0  2145-08-02 08:30:00  33.1     33.10     g/dL   \n",
       "978497  21557581.0  2145-08-02 08:30:00    92     92.00       fL   \n",
       "978498  21557581.0  2145-08-02 08:30:00   180    180.00     K/uL   \n",
       "978499  21557581.0  2145-08-02 08:30:00  14.5     14.50        %   \n",
       "978500  21557581.0  2145-08-02 08:30:00  3.26      3.26     m/uL   \n",
       "978501  21557581.0  2145-08-02 08:30:00   8.4      8.40     K/uL   \n",
       "978502  21557581.0  2145-08-02 08:30:00  47.9     47.90       fL   \n",
       "\n",
       "        ref_range_lower  ref_range_upper      flag              label  fluid  \\\n",
       "978493             34.0             45.0  abnormal         Hematocrit  Blood   \n",
       "978494             11.2             15.7  abnormal         Hemoglobin  Blood   \n",
       "978495             26.0             32.0       NaN                MCH  Blood   \n",
       "978496             32.0             37.0       NaN               MCHC  Blood   \n",
       "978497             82.0             98.0       NaN                MCV  Blood   \n",
       "978498            150.0            400.0       NaN     Platelet Count  Blood   \n",
       "978499             10.5             15.5       NaN                RDW  Blood   \n",
       "978500              3.9              5.2  abnormal    Red Blood Cells  Blood   \n",
       "978501              4.0             10.0       NaN  White Blood Cells  Blood   \n",
       "978502             35.1             46.3  abnormal             RDW-SD  Blood   \n",
       "\n",
       "                 examination_group analysis_batch_id qc_flag  \\\n",
       "978493  Complete Blood Count (CBC)   BATCH_214508_Y8      OK   \n",
       "978494  Complete Blood Count (CBC)   BATCH_214508_D7      OK   \n",
       "978495  Complete Blood Count (CBC)   BATCH_214508_J8    WARN   \n",
       "978496  Complete Blood Count (CBC)   BATCH_214508_O5      OK   \n",
       "978497  Complete Blood Count (CBC)   BATCH_214508_M3      OK   \n",
       "978498  Complete Blood Count (CBC)   BATCH_214508_B1      OK   \n",
       "978499  Complete Blood Count (CBC)   BATCH_214508_H5      OK   \n",
       "978500  Complete Blood Count (CBC)   BATCH_214508_N7      OK   \n",
       "978501  Complete Blood Count (CBC)   BATCH_214508_Y6      OK   \n",
       "978502  Complete Blood Count (CBC)   BATCH_214508_P9      OK   \n",
       "\n",
       "                   ref_range  \n",
       "978493  Normal range: 70-110  \n",
       "978494                   NaN  \n",
       "978495                   NaN  \n",
       "978496                   NaN  \n",
       "978497                   NaN  \n",
       "978498                   NaN  \n",
       "978499                   NaN  \n",
       "978500                   NaN  \n",
       "978501                   NaN  \n",
       "978502                   NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2345f387",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4912eb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hadm_id', 'charttime', 'value', 'valuenum', 'valueuom',\n",
       "       'ref_range_lower', 'ref_range_upper', 'flag', 'label', 'fluid',\n",
       "       'examination_group', 'analysis_batch_id', 'qc_flag', 'ref_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3295c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "      <th>fluid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.00</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>29.0</td>\n",
       "      <td>201.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creatine Kinase (CK)</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>ng/mL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creatine Kinase, MB Isoenzyme</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>ng/mL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Troponin T</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.10</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>INR(PT)</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.80</td>\n",
       "      <td>sec</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.50</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>PT</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>85.8</td>\n",
       "      <td>85.80</td>\n",
       "      <td>sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>PTT</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.10</td>\n",
       "      <td>%</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.90</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>% Hemoglobin A1c</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186.00</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>91.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>eAG</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anion Gap</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Bicarbonate</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id            charttime value  valuenum valueuom  ref_range_lower  \\\n",
       "0  29654838.0  2188-01-04 23:43:00   NaN    198.00     IU/L             29.0   \n",
       "1  29654838.0  2188-01-04 23:43:00   5.0      5.00    ng/mL              0.0   \n",
       "2  29654838.0  2188-01-04 23:43:00   NaN      0.03    ng/mL              0.0   \n",
       "3  29654838.0  2188-01-05 06:56:00   1.2      1.20      NaN              0.9   \n",
       "4  29654838.0  2188-01-05 06:56:00  12.8     12.80      sec              9.4   \n",
       "5  29654838.0  2188-01-05 06:56:00  85.8     85.80      sec             25.0   \n",
       "6  29654838.0  2188-01-05 06:56:00   NaN      8.10        %              4.8   \n",
       "7  29654838.0  2188-01-05 06:56:00   NaN    186.00    mg/dL             91.0   \n",
       "8  29654838.0  2188-01-05 06:56:00  19.0     19.00    mEq/L              8.0   \n",
       "9  29654838.0  2188-01-05 06:56:00  20.0     20.00    mEq/L             22.0   \n",
       "\n",
       "   ref_range_upper      flag                          label  fluid  \n",
       "0           201.00       NaN           Creatine Kinase (CK)  Blood  \n",
       "1            10.00       NaN  Creatine Kinase, MB Isoenzyme  Blood  \n",
       "2             0.01  abnormal                     Troponin T  Blood  \n",
       "3             1.10  abnormal                        INR(PT)  Blood  \n",
       "4            12.50  abnormal                             PT  Blood  \n",
       "5            36.50  abnormal                            PTT  Blood  \n",
       "6             5.90  abnormal               % Hemoglobin A1c  Blood  \n",
       "7           123.00  abnormal                            eAG  Blood  \n",
       "8            20.00       NaN                      Anion Gap  Blood  \n",
       "9            32.00  abnormal                    Bicarbonate  Blood  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[:10]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9516e608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>examination_group</th>\n",
       "      <th>analysis_batch_id</th>\n",
       "      <th>qc_flag</th>\n",
       "      <th>ref_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cardiac Markers</td>\n",
       "      <td>BATCH_218801_N3</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardiac Markers</td>\n",
       "      <td>BATCH_218801_C7</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardiac Markers</td>\n",
       "      <td>BATCH_218801_R4</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coagulation and Hemostasis</td>\n",
       "      <td>BATCH_218801_K7</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coagulation and Hemostasis</td>\n",
       "      <td>BATCH_218801_B1</td>\n",
       "      <td>WARN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coagulation and Hemostasis</td>\n",
       "      <td>BATCH_218801_R1</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HbA1c</td>\n",
       "      <td>BATCH_218801_O1</td>\n",
       "      <td>OK</td>\n",
       "      <td>Normal range: 70-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HbA1c</td>\n",
       "      <td>BATCH_218801_P4</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Renal Function Tests</td>\n",
       "      <td>BATCH_218801_O5</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BMP</td>\n",
       "      <td>BATCH_218801_A1</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            examination_group analysis_batch_id qc_flag             ref_range\n",
       "0             Cardiac Markers   BATCH_218801_N3      OK                   NaN\n",
       "1             Cardiac Markers   BATCH_218801_C7      OK                   NaN\n",
       "2             Cardiac Markers   BATCH_218801_R4      OK                   NaN\n",
       "3  Coagulation and Hemostasis   BATCH_218801_K7      OK                   NaN\n",
       "4  Coagulation and Hemostasis   BATCH_218801_B1    WARN                   NaN\n",
       "5  Coagulation and Hemostasis   BATCH_218801_R1      OK                   NaN\n",
       "6                       HbA1c   BATCH_218801_O1      OK  Normal range: 70-110\n",
       "7                       HbA1c   BATCH_218801_P4      OK                   NaN\n",
       "8        Renal Function Tests   BATCH_218801_O5      OK                   NaN\n",
       "9                         BMP   BATCH_218801_A1      OK                   NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[10:]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4898f",
   "metadata": {},
   "source": [
    "## C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90151aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hadm_id', 'charttime', 'value', 'valuenum', 'valueuom',\n",
       "       'ref_range_lower', 'ref_range_upper', 'flag', 'label', 'fluid',\n",
       "       'examination_group', 'analysis_batch_id', 'qc_flag', 'ref_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c6b2808f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 978503 entries, 0 to 978502\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   hadm_id            978503 non-null  float64\n",
      " 1   charttime          978503 non-null  object \n",
      " 2   value              934025 non-null  object \n",
      " 3   valuenum           907317 non-null  float64\n",
      " 4   valueuom           884585 non-null  object \n",
      " 5   ref_range_lower    865544 non-null  float64\n",
      " 6   ref_range_upper    865544 non-null  float64\n",
      " 7   flag               343687 non-null  object \n",
      " 8   label              978503 non-null  object \n",
      " 9   fluid              978503 non-null  object \n",
      " 10  examination_group  978503 non-null  object \n",
      " 11  analysis_batch_id  978503 non-null  object \n",
      " 12  qc_flag            978503 non-null  object \n",
      " 13  ref_range          146215 non-null  object \n",
      "dtypes: float64(4), object(10)\n",
      "memory usage: 104.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c2c293",
   "metadata": {},
   "source": [
    "# Data Understanding and Preprocessing, cleaning of DF1 - heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4dff0169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d876664a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "      <th>fluid</th>\n",
       "      <th>examination_group</th>\n",
       "      <th>analysis_batch_id</th>\n",
       "      <th>qc_flag</th>\n",
       "      <th>ref_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337781</th>\n",
       "      <td>22665778.0</td>\n",
       "      <td>2114-06-25 17:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Length of Urine Collection</td>\n",
       "      <td>Urine</td>\n",
       "      <td>Urine Test</td>\n",
       "      <td>BATCH_211406_T7</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337786</th>\n",
       "      <td>22665778.0</td>\n",
       "      <td>2114-06-25 17:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Length of Urine Collection</td>\n",
       "      <td>Urine</td>\n",
       "      <td>Urine Test</td>\n",
       "      <td>BATCH_211406_T7</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926329</th>\n",
       "      <td>27638257.0</td>\n",
       "      <td>2189-04-21 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Length of Urine Collection</td>\n",
       "      <td>Urine</td>\n",
       "      <td>Urine Test</td>\n",
       "      <td>BATCH_218904_R6</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926331</th>\n",
       "      <td>27638257.0</td>\n",
       "      <td>2189-04-21 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Length of Urine Collection</td>\n",
       "      <td>Urine</td>\n",
       "      <td>Urine Test</td>\n",
       "      <td>BATCH_218904_R6</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hadm_id            charttime value  valuenum valueuom  \\\n",
       "337781  22665778.0  2114-06-25 17:44:00   NaN       NaN      NaN   \n",
       "337786  22665778.0  2114-06-25 17:44:00   NaN       NaN      NaN   \n",
       "926329  27638257.0  2189-04-21 16:00:00   NaN       NaN      NaN   \n",
       "926331  27638257.0  2189-04-21 16:00:00   NaN       NaN      NaN   \n",
       "\n",
       "        ref_range_lower  ref_range_upper flag                       label  \\\n",
       "337781              NaN              NaN  NaN  Length of Urine Collection   \n",
       "337786              NaN              NaN  NaN  Length of Urine Collection   \n",
       "926329              NaN              NaN  NaN  Length of Urine Collection   \n",
       "926331              NaN              NaN  NaN  Length of Urine Collection   \n",
       "\n",
       "        fluid examination_group analysis_batch_id qc_flag ref_range  \n",
       "337781  Urine        Urine Test   BATCH_211406_T7      OK       NaN  \n",
       "337786  Urine        Urine Test   BATCH_211406_T7      OK       NaN  \n",
       "926329  Urine        Urine Test   BATCH_218904_R6      OK       NaN  \n",
       "926331  Urine        Urine Test   BATCH_218904_R6      OK       NaN  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show duplicated rows\n",
    "df[df.duplicated(keep=False)].sort_values(by=df.columns.tolist()).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5ede83c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "54c08a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 978501 entries, 0 to 978502\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   hadm_id            978501 non-null  float64\n",
      " 1   charttime          978501 non-null  object \n",
      " 2   value              934025 non-null  object \n",
      " 3   valuenum           907317 non-null  float64\n",
      " 4   valueuom           884585 non-null  object \n",
      " 5   ref_range_lower    865544 non-null  float64\n",
      " 6   ref_range_upper    865544 non-null  float64\n",
      " 7   flag               343687 non-null  object \n",
      " 8   label              978501 non-null  object \n",
      " 9   fluid              978501 non-null  object \n",
      " 10  examination_group  978501 non-null  object \n",
      " 11  analysis_batch_id  978501 non-null  object \n",
      " 12  qc_flag            978501 non-null  object \n",
      " 13  ref_range          146215 non-null  object \n",
      "dtypes: float64(4), object(10)\n",
      "memory usage: 112.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91aae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col == 'charttime' or col == 'hadm_id' or col == 'subject_id':\n",
    "        continue\n",
    "    print(f\"{col}: {df[col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e560cfd8",
   "metadata": {},
   "source": [
    "## Check for wrong NaNs / non typical entries in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896cbdf",
   "metadata": {},
   "source": [
    "#### Find wrong NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FIND NON-NUMERICAL ENTRIES IN NUMERICAL COLUMNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identify columns that should be numerical\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nColumns already numeric: {len(numeric_cols)}\")\n",
    "print(numeric_cols)\n",
    "\n",
    "# Check object/string columns that might contain numerical data\n",
    "object_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nObject/String columns to check: {len(object_cols)}\")\n",
    "print(object_cols)\n",
    "\n",
    "# For each object column, try to find non-numerical entries\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKING FOR NON-NUMERICAL ENTRIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "non_numerical_summary = {}\n",
    "\n",
    "for col in object_cols:\n",
    "    non_numerical_entries = []\n",
    "    \n",
    "    for idx, value in df[col].items():\n",
    "        if pd.isna(value):  # Skip NaN/None\n",
    "            continue\n",
    "        \n",
    "        # Try to convert to float\n",
    "        try:\n",
    "            float(value)\n",
    "        except (ValueError, TypeError):\n",
    "            non_numerical_entries.append({\n",
    "                'index': idx,\n",
    "                'value': value,\n",
    "                'type': type(value).__name__\n",
    "            })\n",
    "    \n",
    "    # Store summary\n",
    "    if non_numerical_entries:\n",
    "        non_numerical_summary[col] = non_numerical_entries\n",
    "        \n",
    "        print(f\"\\n{'─'*80}\")\n",
    "        print(f\"Column: '{col}' | Non-numerical entries: {len(non_numerical_entries)}\")\n",
    "        print(f\"{'─'*80}\")\n",
    "        \n",
    "        # Get unique non-numerical values\n",
    "        unique_values = list(set([e['value'] for e in non_numerical_entries]))\n",
    "        print(f\"Unique non-numerical values ({len(unique_values)}):\")\n",
    "        for val in sorted(unique_values)[:20]:  # Show first 20\n",
    "            count = sum(1 for e in non_numerical_entries if e['value'] == val)\n",
    "            print(f\"  • '{val}' — appears {count} times\")\n",
    "        \n",
    "        if len(unique_values) > 20:\n",
    "            print(f\"  ... and {len(unique_values) - 20} more\")\n",
    "        \n",
    "        # Show sample rows\n",
    "        print(f\"\\nSample rows with non-numerical entries:\")\n",
    "        for entry in non_numerical_entries[:5]:\n",
    "            print(f\"  Index {entry['index']}: {entry['value']!r} ({entry['type']})\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nColumns with non-numerical entries: {len(non_numerical_summary)}\")\n",
    "\n",
    "for col, entries in non_numerical_summary.items():\n",
    "    total_rows = len(df)\n",
    "    non_num_count = len(entries)\n",
    "    pct = (non_num_count / total_rows) * 100\n",
    "    unique_count = len(set([e['value'] for e in entries]))\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Non-numerical rows: {non_num_count} ({pct:.2f}%)\")\n",
    "    print(f\"  Unique non-numerical values: {unique_count}\")\n",
    "    print(f\"  Numerical rows: {total_rows - non_num_count}\")\n",
    "\n",
    "# Optional: Create a detailed report\n",
    "if non_numerical_summary:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED REPORT - ALL NON-NUMERICAL ENTRIES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for col in non_numerical_summary:\n",
    "        print(f\"\\n{col}:\")\n",
    "        entries_df = pd.DataFrame(non_numerical_summary[col])\n",
    "        # Count occurrences\n",
    "        value_counts = entries_df['value'].value_counts()\n",
    "        print(value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612aa4de",
   "metadata": {},
   "source": [
    "- valueuom: has '' , remove; Pos/Neg == +/-; U ??\n",
    "- value has wrong entries inspect and extrat if possible to valuenum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287d8135",
   "metadata": {},
   "source": [
    "### Handle Value wrong nans, then extract missing from value into new column valuenum_merged if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c294dd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Column: 'value' | Non-numerical entries: 94777\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Unique non-numerical values (222):\n",
      "  • '/10.' — appears 6 times\n",
      "  • '/11.' — appears 3 times\n",
      "  • '/12.' — appears 17 times\n",
      "  • '/13.' — appears 6 times\n",
      "  • '/14.' — appears 14 times\n",
      "  • '/15.' — appears 9 times\n",
      "  • '/16.' — appears 30 times\n",
      "  • '/17.' — appears 13 times\n",
      "  • '/18.' — appears 29 times\n",
      "  • '/19.' — appears 7 times\n",
      "  • '/20.' — appears 23 times\n",
      "  • '/21.' — appears 10 times\n",
      "  • '/22.' — appears 13 times\n",
      "  • '/23.' — appears 6 times\n",
      "  • '/24.' — appears 21 times\n",
      "  • '/25.' — appears 18 times\n",
      "  • '/26.' — appears 6 times\n",
      "  • '/27.' — appears 8 times\n",
      "  • '/28.' — appears 5 times\n",
      "  • '/29.' — appears 1 times\n",
      "  • '/30.' — appears 9 times\n",
      "  • '/31.' — appears 5 times\n",
      "  • '/32.' — appears 6 times\n",
      "  • '/33.' — appears 2 times\n",
      "  • '/34.' — appears 1 times\n",
      "  • '/35.' — appears 1 times\n",
      "  • '/36.' — appears 1 times\n",
      "  • '/38.' — appears 1 times\n",
      "  • '/4 .' — appears 1 times\n",
      "  • '/42.' — appears 1 times\n",
      "  • '/44.' — appears 1 times\n",
      "  • '/6 .' — appears 1 times\n",
      "  • '/7 .' — appears 1 times\n",
      "  • '/8 .' — appears 4 times\n",
      "  • '0-10' — appears 9 times\n",
      "  • '0-2' — appears 585 times\n",
      "  • '0/10.' — appears 1 times\n",
      "  • '0/15.' — appears 1 times\n",
      "  • '0/16.' — appears 2 times\n",
      "  • '0/18.' — appears 1 times\n",
      "  • '0/19.' — appears 2 times\n",
      "  • '0/20.' — appears 1 times\n",
      "  • '0/22.' — appears 3 times\n",
      "  • '0/28.' — appears 1 times\n",
      "  • '0/32.' — appears 2 times\n",
      "  • '1.0.14' — appears 1 times\n",
      "  • '10-40' — appears 5 times\n",
      "  • '10/.' — appears 4 times\n",
      "  • '11-20' — appears 57 times\n",
      "  • '12/.' — appears 9 times\n",
      "  • '12/0.' — appears 2 times\n",
      "  • '12/12.' — appears 1 times\n",
      "  • '12/13.' — appears 1 times\n",
      "  • '12/2.' — appears 4 times\n",
      "  • '12/4.' — appears 4 times\n",
      "  • '12/6.' — appears 3 times\n",
      "  • '12/7.' — appears 1 times\n",
      "  • '12/8.' — appears 5 times\n",
      "  • '13/.' — appears 3 times\n",
      "  • '14/.' — appears 20 times\n",
      "  • '14/0.' — appears 5 times\n",
      "  • '14/1.' — appears 1 times\n",
      "  • '14/2.' — appears 1 times\n",
      "  • '14/3.' — appears 2 times\n",
      "  • '14/4.' — appears 3 times\n",
      "  • '14/5.' — appears 1 times\n",
      "  • '14/6.' — appears 1 times\n",
      "  • '14/8.' — appears 1 times\n",
      "  • '14/9.' — appears 1 times\n",
      "  • '15/.' — appears 6 times\n",
      "  • '15/0.' — appears 2 times\n",
      "  • '16/.' — appears 32 times\n",
      "  • '16/0.' — appears 14 times\n",
      "  • '16/10.' — appears 1 times\n",
      "  • '16/12.' — appears 1 times\n",
      "  • '16/15.' — appears 1 times\n",
      "  • '16/18.' — appears 1 times\n",
      "  • '16/2.' — appears 7 times\n",
      "  • '16/20.' — appears 1 times\n",
      "  • '16/25.' — appears 1 times\n",
      "  • '16/3.' — appears 1 times\n",
      "  • '16/4.' — appears 4 times\n",
      "  • '16/5.' — appears 2 times\n",
      "  • '16/6.' — appears 1 times\n",
      "  • '16/8.' — appears 1 times\n",
      "  • '17/.' — appears 1 times\n",
      "  • '18/.' — appears 29 times\n",
      "  • '18/0.' — appears 5 times\n",
      "  • '18/18.' — appears 1 times\n",
      "  • '18/2.' — appears 3 times\n",
      "  • '18/3.' — appears 1 times\n",
      "  • '18/5.' — appears 2 times\n",
      "  • '18/6.' — appears 1 times\n",
      "  • '18/9.' — appears 1 times\n",
      "  • '19/.' — appears 2 times\n",
      "  • '20/.' — appears 21 times\n",
      "  • '20/0.' — appears 10 times\n",
      "  • '20/1.' — appears 1 times\n",
      "  • '20/10.' — appears 1 times\n",
      "  • '20/4.' — appears 3 times\n",
      "  • '20/5.' — appears 1 times\n",
      "  • '20/8.' — appears 1 times\n",
      "  • '21-50' — appears 58 times\n",
      "  • '21/.' — appears 1 times\n",
      "  • '22/.' — appears 20 times\n",
      "  • '22/0.' — appears 4 times\n",
      "  • '22/1.' — appears 1 times\n",
      "  • '22/2.' — appears 2 times\n",
      "  • '22/3.' — appears 5 times\n",
      "  • '22/4.' — appears 1 times\n",
      "  • '22/5.' — appears 1 times\n",
      "  • '22/6.' — appears 1 times\n",
      "  • '23/.' — appears 4 times\n",
      "  • '24/.' — appears 7 times\n",
      "  • '24/0.' — appears 1 times\n",
      "  • '24/1.' — appears 1 times\n",
      "  • '24/2.' — appears 1 times\n",
      "  • '24/3.' — appears 1 times\n",
      "  • '24/4.' — appears 1 times\n",
      "  • '25/.' — appears 1 times\n",
      "  • '26/.' — appears 9 times\n",
      "  • '26/0.' — appears 4 times\n",
      "  • '26/2.' — appears 1 times\n",
      "  • '26/5.' — appears 1 times\n",
      "  • '27/.' — appears 1 times\n",
      "  • '28/.' — appears 1 times\n",
      "  • '28/0.' — appears 2 times\n",
      "  • '28/4.' — appears 1 times\n",
      "  • '28/5.' — appears 1 times\n",
      "  • '3-5' — appears 207 times\n",
      "  • '3.-5' — appears 1 times\n",
      "  • '30/.' — appears 2 times\n",
      "  • '30/0.' — appears 5 times\n",
      "  • '30/1.' — appears 2 times\n",
      "  • '30/2.' — appears 1 times\n",
      "  • '36/.' — appears 1 times\n",
      "  • '36/0.' — appears 1 times\n",
      "  • '38/.' — appears 1 times\n",
      "  • '40-80' — appears 6 times\n",
      "  • '6-10' — appears 101 times\n",
      "  • '8/ .' — appears 1 times\n",
      "  • '80-160' — appears 1 times\n",
      "  • '9/ .' — appears 1 times\n",
      "  • '<1' — appears 42 times\n",
      "  • '>1.030' — appears 1 times\n",
      "  • '>1.035' — appears 5 times\n",
      "  • '>1.050' — appears 1 times\n",
      "  • '>1000' — appears 3 times\n",
      "  • '>300' — appears 21 times\n",
      "  • '>50' — appears 101 times\n",
      "  • '>=1.035' — appears 3 times\n",
      "  • 'A' — appears 1 times\n",
      "  • 'AMBER' — appears 4 times\n",
      "  • 'ART.' — appears 6348 times\n",
      "  • 'Amber' — appears 43 times\n",
      "  • 'BROWN' — appears 3 times\n",
      "  • 'Brown' — appears 5 times\n",
      "  • 'CANCEL' — appears 1 times\n",
      "  • 'CENTRAL VENOUS.' — appears 221 times\n",
      "  • 'CLEAN' — appears 1 times\n",
      "  • 'CLOUDY' — appears 4 times\n",
      "  • 'CONTROLLED.' — appears 684 times\n",
      "  • 'Clear' — appears 480 times\n",
      "  • 'Cloudy' — appears 63 times\n",
      "  • 'D' — appears 37 times\n",
      "  • 'DKAM' — appears 1 times\n",
      "  • 'DKAMB' — appears 4 times\n",
      "  • 'DKAMBER' — appears 1 times\n",
      "  • 'DKMB' — appears 1 times\n",
      "  • 'DKYELLO' — appears 1 times\n",
      "  • 'DONE' — appears 274 times\n",
      "  • 'DUE TO ABNORMAL URINE COLOR, INTERPRET DIPSTICK RESULTS WITH CAUTION' — appears 2 times\n",
      "  • 'DUE TO ABNORMAL URINE COLOR, INTERPRET DIPSTICK WITH CAUTION' — appears 1 times\n",
      "  • 'DkAmb' — appears 3 times\n",
      "  • 'ERROR' — appears 6 times\n",
      "  • 'EXTRAC' — appears 1 times\n",
      "  • 'FEW' — appears 195 times\n",
      "  • 'HOLD.' — appears 239 times\n",
      "  • 'HOLD.  DISCARD AFTER THREE DAYS .' — appears 5 times\n",
      "  • 'HOLD.  DISCARD GREATER THAN 24 HRS OLD.' — appears 351 times\n",
      "  • 'HOLD.  DISCARD GREATER THAN 4 HOURS OLD.' — appears 437 times\n",
      "  • 'HOLD.  SPECIMEN TO BE HELD 48 HOURS AND DISCARDED.' — appears 462 times\n",
      "  • 'Hazy' — appears 82 times\n",
      "  • 'I/E' — appears 5 times\n",
      "  • 'IDENTIFIED AS ARTIFACT' — appears 1 times\n",
      "  • 'IMV.' — appears 5 times\n",
      "  • 'INTRAC' — appears 4 times\n",
      "  • 'INTUBATED.' — appears 1576 times\n",
      "  • 'LG' — appears 242 times\n",
      "  • 'LGE' — appears 5 times\n",
      "  • 'LtAmb' — appears 1 times\n",
      "  • 'MANY' — appears 74 times\n",
      "  • 'MIX.' — appears 2173 times\n",
      "  • 'MOD' — appears 227 times\n",
      "  • 'N' — appears 1 times\n",
      "  • 'NEEDLE' — appears 7 times\n",
      "  • 'NEG' — appears 4234 times\n",
      "  • 'NEGATIVE' — appears 11 times\n",
      "  • 'NONE' — appears 2070 times\n",
      "  • 'NORMAL' — appears 1 times\n",
      "  • 'NOT INTUBATED.' — appears 686 times\n",
      "  • 'O' — appears 1 times\n",
      "  • 'OCC' — appears 80 times\n",
      "  • 'Orange' — appears 7 times\n",
      "  • 'PINK' — appears 1 times\n",
      "  • 'POS' — appears 107 times\n",
      "  • 'RANDOM' — appears 4 times\n",
      "  • 'RARE' — appears 71 times\n",
      "  • 'RARE/VERIFIED' — appears 1 times\n",
      "  • 'RED' — appears 22 times\n",
      "  • 'RHOMBOID' — appears 3 times\n",
      "  • 'Red' — appears 22 times\n",
      "  • 'SEDIMENT DONE ON LESS THAN 5 MLS.' — appears 1 times\n",
      "  • 'SM' — appears 166 times\n",
      "  • 'SPONTANEOUS.' — appears 175 times\n",
      "  • 'SlHazy' — appears 4 times\n",
      "  • 'Straw' — appears 101 times\n",
      "  • 'TR' — appears 326 times\n",
      "  • 'VEN.' — appears 1476 times\n",
      "  • 'YELLOW' — appears 4 times\n",
      "  • 'Yellow' — appears 452 times\n",
      "  • '___' — appears 68645 times\n"
     ]
    }
   ],
   "source": [
    "# chec k only value column: show all unique non-numerical entries in 'value' column\n",
    "non_numerical_values = []\n",
    "for idx, value in df['value'].items():\n",
    "    if pd.isna(value):  # Skip NaN/None\n",
    "        continue\n",
    "    \n",
    "    # Try to convert to float\n",
    "    try:\n",
    "        float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        non_numerical_values.append({\n",
    "            'index': idx,\n",
    "            'value': value,\n",
    "            'type': type(value).__name__\n",
    "        })\n",
    "print(f\"\\n{'─'*80}\")\n",
    "print(f\"Column: 'value' | Non-numerical entries: {len(non_numerical_values)}\")\n",
    "print(f\"{'─'*80}\")\n",
    "# Get unique non-numerical values\n",
    "unique_values = list(set([e['value'] for e in non_numerical_values]))\n",
    "print(f\"Unique non-numerical values ({len(unique_values)}):\")\n",
    "for val in sorted(unique_values):\n",
    "    count = sum(1 for e in non_numerical_values if e['value'] == val)\n",
    "    print(f\"  • '{val}' — appears {count} times\")   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f56c14",
   "metadata": {},
   "source": [
    "FINDINGS\n",
    "\n",
    "=> in col value, We want to convert '___' and 'NONE' 'ERROR' to np.nan!\n",
    "\n",
    "=> then we create a new col value_extracted (float64) out of col value where:\n",
    "- we can calculate as float complete / like 20/0 but only if there is anumber before and after the /! => complete\n",
    "- we can take the middle point of complete ranges like '80-160'\n",
    "- we can calculate a float value of comparisons with < > by sub/add 0.1 to the number, eg. '>1.050' => 1.150 or '<1' => 0.9\n",
    "- the rest is to nuemic error coerce put to NaN.\n",
    "\n",
    "=> then, we fill np.nan entries in col valuenum with values from valUe_extracted if they are not nan and tell me the amount of filled rows and show examples beffore and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0a9447f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24056"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first sanity check if needed\n",
    "# check are there rows where valuenum has nan but value has a value?a\n",
    "len(df[(df['valuenum'].isna()) & (df['value'].notna())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6e4d233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: CONVERT PLACEHOLDER STRINGS TO NaN\n",
      "================================================================================\n",
      "\n",
      "Placeholders to convert: ['___', 'NONE', 'ERROR']\n",
      "Before: 44476 NaN values\n",
      "  Converted '___': 68645 rows\n",
      "  Converted 'NONE': 2070 rows\n",
      "  Converted 'ERROR': 6 rows\n",
      "After: 115197 NaN values\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 1: CONVERT PLACEHOLDER STRINGS TO NaN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define placeholder patterns\n",
    "placeholders = ['___', 'NONE', 'ERROR']\n",
    "\n",
    "print(f\"\\nPlaceholders to convert: {placeholders}\")\n",
    "print(f\"Before: {df['value'].isna().sum()} NaN values\")\n",
    "\n",
    "# Convert placeholders to NaN (case-insensitive)\n",
    "for placeholder in placeholders:\n",
    "    mask = df['value'].astype(str).str.lower() == placeholder.lower()\n",
    "    count = mask.sum()\n",
    "    df.loc[mask, 'value'] = np.nan\n",
    "    print(f\"  Converted '{placeholder}': {count} rows\")\n",
    "\n",
    "print(f\"After: {df['value'].isna().sum()} NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d311ace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 2: EXTRACT NUMERIC VALUES FROM 'value' COLUMN\n",
      "================================================================================\n",
      "\n",
      "Extraction complete!\n",
      "Non-null values extracted: 840,559\n",
      "Failed extractions (NaN): 137,942\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 2: EXTRACT NUMERIC VALUES FROM 'value' COLUMN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def extract_numeric_from_value(x):\n",
    "    \"\"\"\n",
    "    Extract numeric values from various string formats:\n",
    "    - Simple numbers: '123' => 123\n",
    "    - Decimals: '123.45' => 123.45\n",
    "    - Divisions: '20/10' => 2.0\n",
    "    - Ranges: '80-160' => 120 (midpoint)\n",
    "    - Comparisons: '>1.050' => 1.150, '<1' => 0.9\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    x_str = str(x).strip()\n",
    "    \n",
    "    # Try direct float conversion\n",
    "    try:\n",
    "        return float(x_str)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # Handle divisions (e.g., '20/10')\n",
    "    if '/' in x_str:\n",
    "        parts = x_str.split('/')\n",
    "        try:\n",
    "            if len(parts) == 2 and parts[0].strip() and parts[1].strip():\n",
    "                num1 = float(parts[0].strip())\n",
    "                num2 = float(parts[1].strip())\n",
    "                if num2 != 0:  # Avoid division by zero\n",
    "                    return num1 / num2\n",
    "        except (ValueError, ZeroDivisionError):\n",
    "            pass\n",
    "    \n",
    "    # Handle ranges (e.g., '80-160')\n",
    "    if '-' in x_str and not x_str.startswith('-'):\n",
    "        parts = x_str.split('-')\n",
    "        try:\n",
    "            if len(parts) == 2 and parts[0].strip() and parts[1].strip():\n",
    "                num1 = float(parts[0].strip())\n",
    "                num2 = float(parts[1].strip())\n",
    "                return (num1 + num2) / 2  # Midpoint\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # Handle comparisons (e.g., '>1.050' => 1.150, '<1' => 0.9)\n",
    "    comparison_match = re.match(r'^([<>]=?)(\\d*\\.?\\d+)$', x_str.strip())\n",
    "    if comparison_match:\n",
    "        operator = comparison_match.group(1)\n",
    "        try:\n",
    "            num = float(comparison_match.group(2))\n",
    "            if operator == '>':\n",
    "                return num + 0.1\n",
    "            elif operator == '>=':\n",
    "                return num\n",
    "            elif operator == '<':\n",
    "                return num - 0.1\n",
    "            elif operator == '<=':\n",
    "                return num\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # If nothing worked, return NaN\n",
    "    return np.nan\n",
    "\n",
    "# Apply extraction\n",
    "df['value_extracted'] = df['value'].apply(extract_numeric_from_value)\n",
    "\n",
    "print(f\"\\nExtraction complete!\")\n",
    "print(f\"Non-null values extracted: {df['value_extracted'].notna().sum():,}\")\n",
    "print(f\"Failed extractions (NaN): {df['value_extracted'].isna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ce5913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 3: SHOW EXAMPLES OF EXTRACTED VALUES (Complex Formats Only)\n",
      "================================================================================\n",
      "\n",
      "Total rows with extracted values: 840,559\n",
      "\n",
      "================================================================================\n",
      "EXAMPLES: COMPARISONS (>, <, >=, <=)\n",
      "================================================================================\n",
      "\n",
      "Found 177 comparison values\n",
      "\n",
      "Original             Extracted       Logic                                   \n",
      "───────────────────────────────────────────────────────────────────────────\n",
      "<1                   0.900           '<1' → 1.0 - 0.1 = 0.9                  \n",
      ">=1.035              1.035           '>=1.035' → value as-is                 \n",
      ">50                  50.100          '>50' → 50.0 + 0.1 = 50.1               \n",
      ">300                 300.100         '>300' → 300.0 + 0.1 = 300.1            \n",
      ">1.035               1.135           '>1.035' → 1.035 + 0.1 = 1.135          \n",
      ">1.030               1.130           '>1.030' → 1.03 + 0.1 = 1.1300000000000001\n",
      ">1000                1000.100        '>1000' → 1000.0 + 0.1 = 1000.1         \n",
      ">1.050               1.150           '>1.050' → 1.05 + 0.1 = 1.1500000000000001\n",
      "\n",
      "================================================================================\n",
      "EXAMPLES: RANGES (e.g., 80-160, 0-2)\n",
      "================================================================================\n",
      "\n",
      "Found 1030 range values\n",
      "\n",
      "Original             Extracted       Logic (Midpoint)                        \n",
      "───────────────────────────────────────────────────────────────────────────\n",
      "0-2                  1.000           (0.0 + 2.0) / 2 = 1.0                   \n",
      "6-10                 8.000           (6.0 + 10.0) / 2 = 8.0                  \n",
      "11-20                15.500          (11.0 + 20.0) / 2 = 15.5                \n",
      "3-5                  4.000           (3.0 + 5.0) / 2 = 4.0                   \n",
      "10-40                25.000          (10.0 + 40.0) / 2 = 25.0                \n",
      "21-50                35.500          (21.0 + 50.0) / 2 = 35.5                \n",
      "0-10                 5.000           (0.0 + 10.0) / 2 = 5.0                  \n",
      "40-80                60.000          (40.0 + 80.0) / 2 = 60.0                \n",
      "3.-5                 4.000           (3.0 + 5.0) / 2 = 4.0                   \n",
      "80-160               120.000         (80.0 + 160.0) / 2 = 120.0              \n",
      "\n",
      "================================================================================\n",
      "EXAMPLES: DIVISIONS (e.g., 20/10, 15/3)\n",
      "================================================================================\n",
      "\n",
      "Found 104 division values\n",
      "\n",
      "Original             Extracted       Logic                                   \n",
      "───────────────────────────────────────────────────────────────────────────\n",
      "20/4.                5.000           20.0 / 4.0 = 5.0                        \n",
      "14/4.                3.500           14.0 / 4.0 = 3.5                        \n",
      "0/10.                0.000           0.0 / 10.0 = 0.0                        \n",
      "12/12.               1.000           12.0 / 12.0 = 1.0                       \n",
      "12/4.                3.000           12.0 / 4.0 = 3.0                        \n",
      "0/22.                0.000           0.0 / 22.0 = 0.0                        \n",
      "24/1.                24.000          24.0 / 1.0 = 24.0                       \n",
      "14/3.                4.667           14.0 / 3.0 = 4.666666666666667          \n",
      "14/1.                14.000          14.0 / 1.0 = 14.0                       \n",
      "0/32.                0.000           0.0 / 32.0 = 0.0                        \n",
      "20/8.                2.500           20.0 / 8.0 = 2.5                        \n",
      "14/2.                7.000           14.0 / 2.0 = 7.0                        \n",
      "16/2.                8.000           16.0 / 2.0 = 8.0                        \n",
      "30/1.                30.000          30.0 / 1.0 = 30.0                       \n",
      "30/2.                15.000          30.0 / 2.0 = 15.0                       \n",
      "\n",
      "================================================================================\n",
      "EXTRACTION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total extracted values: 840,559\n",
      "  • Comparisons:  177 (0.0%)\n",
      "  • Ranges:       1,030 (0.1%)\n",
      "  • Divisions:    104 (0.0%)\n",
      "  • Other:        839,248\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "STATISTICS OF EXTRACTED VALUES\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "count    840559.000000\n",
      "mean         56.076593\n",
      "std        2220.833420\n",
      "min        -743.000000\n",
      "25%           4.200000\n",
      "50%          16.000000\n",
      "75%          43.000000\n",
      "max      886449.000000\n",
      "Name: value_extracted, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 3: SHOW EXAMPLES OF EXTRACTED VALUES (Complex Formats Only)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find rows with successful extractions\n",
    "extracted_rows = df[df['value_extracted'].notna() & df['value'].notna()].copy()\n",
    "\n",
    "print(f\"\\nTotal rows with extracted values: {len(extracted_rows):,}\\n\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# COMPARISONS: >, <, >=, <=\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "print(\"=\"*80)\n",
    "print(\"EXAMPLES: COMPARISONS (>, <, >=, <=)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_pattern = r'^([<>]=?)(\\d*\\.?\\d+)$'\n",
    "comparison_examples = []\n",
    "\n",
    "for idx, row in extracted_rows.iterrows():\n",
    "    original = str(row['value']).strip()\n",
    "    if re.match(comparison_pattern, original):\n",
    "        comparison_examples.append({\n",
    "            'original': original,\n",
    "            'extracted': row['value_extracted']\n",
    "        })\n",
    "\n",
    "if comparison_examples:\n",
    "    # Show first 15 unique examples\n",
    "    unique_comparisons = []\n",
    "    seen = set()\n",
    "    for ex in comparison_examples:\n",
    "        if ex['original'] not in seen:\n",
    "            unique_comparisons.append(ex)\n",
    "            seen.add(ex['original'])\n",
    "            if len(unique_comparisons) >= 15:\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nFound {len(comparison_examples)} comparison values\\n\")\n",
    "    print(f\"{'Original':<20} {'Extracted':<15} {'Logic':<40}\")\n",
    "    print(\"─\" * 75)\n",
    "    \n",
    "    for ex in unique_comparisons:\n",
    "        original = ex['original']\n",
    "        extracted = ex['extracted']\n",
    "        \n",
    "        # Explain the logic\n",
    "        if original.startswith('>'):\n",
    "            if original.startswith('>='):\n",
    "                logic = f\"'{original}' → value as-is\"\n",
    "            else:\n",
    "                num = float(original[1:])\n",
    "                logic = f\"'{original}' → {num} + 0.1 = {extracted}\"\n",
    "        elif original.startswith('<'):\n",
    "            if original.startswith('<='):\n",
    "                logic = f\"'{original}' → value as-is\"\n",
    "            else:\n",
    "                num = float(original[1:])\n",
    "                logic = f\"'{original}' → {num} - 0.1 = {extracted}\"\n",
    "        \n",
    "        print(f\"{original:<20} {extracted:<15.3f} {logic:<40}\")\n",
    "else:\n",
    "    print(\"\\nNo comparison values found\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# RANGES: 80-160, 0-2, etc.\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLES: RANGES (e.g., 80-160, 0-2)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "range_pattern = r'^(\\d+\\.?\\d*)-(\\d+\\.?\\d*)$'\n",
    "range_examples = []\n",
    "\n",
    "for idx, row in extracted_rows.iterrows():\n",
    "    original = str(row['value']).strip()\n",
    "    if re.match(range_pattern, original) and not original.startswith('-'):\n",
    "        range_examples.append({\n",
    "            'original': original,\n",
    "            'extracted': row['value_extracted']\n",
    "        })\n",
    "\n",
    "if range_examples:\n",
    "    # Show first 15 unique examples\n",
    "    unique_ranges = []\n",
    "    seen = set()\n",
    "    for ex in range_examples:\n",
    "        if ex['original'] not in seen:\n",
    "            unique_ranges.append(ex)\n",
    "            seen.add(ex['original'])\n",
    "            if len(unique_ranges) >= 15:\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nFound {len(range_examples)} range values\\n\")\n",
    "    print(f\"{'Original':<20} {'Extracted':<15} {'Logic (Midpoint)':<40}\")\n",
    "    print(\"─\" * 75)\n",
    "    \n",
    "    for ex in unique_ranges:\n",
    "        original = ex['original']\n",
    "        extracted = ex['extracted']\n",
    "        \n",
    "        # Calculate and show logic\n",
    "        parts = original.split('-')\n",
    "        num1 = float(parts[0])\n",
    "        num2 = float(parts[1])\n",
    "        midpoint = (num1 + num2) / 2\n",
    "        \n",
    "        logic = f\"({num1} + {num2}) / 2 = {midpoint}\"\n",
    "        \n",
    "        print(f\"{original:<20} {extracted:<15.3f} {logic:<40}\")\n",
    "else:\n",
    "    print(\"\\nNo range values found\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# DIVISIONS: 20/10, 15/3, etc.\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXAMPLES: DIVISIONS (e.g., 20/10, 15/3)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "division_pattern = r'^(\\d+\\.?\\d*)/(\\d+\\.?\\d*)$'\n",
    "division_examples = []\n",
    "\n",
    "for idx, row in extracted_rows.iterrows():\n",
    "    original = str(row['value']).strip()\n",
    "    if re.match(division_pattern, original):\n",
    "        division_examples.append({\n",
    "            'original': original,\n",
    "            'extracted': row['value_extracted']\n",
    "        })\n",
    "\n",
    "if division_examples:\n",
    "    # Show first 15 unique examples\n",
    "    unique_divisions = []\n",
    "    seen = set()\n",
    "    for ex in division_examples:\n",
    "        if ex['original'] not in seen:\n",
    "            unique_divisions.append(ex)\n",
    "            seen.add(ex['original'])\n",
    "            if len(unique_divisions) >= 15:\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nFound {len(division_examples)} division values\\n\")\n",
    "    print(f\"{'Original':<20} {'Extracted':<15} {'Logic':<40}\")\n",
    "    print(\"─\" * 75)\n",
    "    \n",
    "    for ex in unique_divisions:\n",
    "        original = ex['original']\n",
    "        extracted = ex['extracted']\n",
    "        \n",
    "        # Calculate and show logic\n",
    "        parts = original.split('/')\n",
    "        num1 = float(parts[0])\n",
    "        num2 = float(parts[1])\n",
    "        result = num1 / num2 if num2 != 0 else float('nan')\n",
    "        \n",
    "        logic = f\"{num1} / {num2} = {result}\"\n",
    "        \n",
    "        print(f\"{original:<20} {extracted:<15.3f} {logic:<40}\")\n",
    "else:\n",
    "    print(\"\\nNo division values found\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# SUMMARY STATISTICS\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXTRACTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTotal extracted values: {len(extracted_rows):,}\")\n",
    "print(f\"  • Comparisons:  {len(comparison_examples):,} ({len(comparison_examples)/len(extracted_rows)*100:.1f}%)\")\n",
    "print(f\"  • Ranges:       {len(range_examples):,} ({len(range_examples)/len(extracted_rows)*100:.1f}%)\")\n",
    "print(f\"  • Divisions:    {len(division_examples):,} ({len(division_examples)/len(extracted_rows)*100:.1f}%)\")\n",
    "print(f\"  • Other:        {len(extracted_rows) - len(comparison_examples) - len(range_examples) - len(division_examples):,}\")\n",
    "\n",
    "print(f\"\\n{'─'*80}\")\n",
    "print(\"STATISTICS OF EXTRACTED VALUES\")\n",
    "print(f\"{'─'*80}\")\n",
    "print(df['value_extracted'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c49fed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 4: MERGE valuenum + value_extracted\n",
      "================================================================================\n",
      "\n",
      "Before merge:\n",
      "  valuenum (non-null):           907,317\n",
      "  value_extracted (non-null):    840,559\n",
      "  Can be filled from extraction:  1,311\n",
      "\n",
      "After merge:\n",
      "  valuenum_merged (non-null):   908,628\n",
      "  Newly filled from extraction:   1,311 (+0.13%)\n",
      "  Total improvement:              837,444 rows\n",
      "\n",
      "Data type: float64\n",
      "\n",
      "Statistics:\n",
      "count    908628.000000\n",
      "mean         67.258029\n",
      "std        2174.021247\n",
      "min        -743.000000\n",
      "25%           4.300000\n",
      "50%          17.000000\n",
      "75%          60.000000\n",
      "max      886449.000000\n",
      "Name: valuenum_merged, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 4: MERGE valuenum + value_extracted\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Store counts before merge\n",
    "valuenum_before = df['valuenum'].notna().sum()\n",
    "value_extracted_only = (df['valuenum'].isna() & df['value_extracted'].notna()).sum()\n",
    "\n",
    "print(f\"\\nBefore merge:\")\n",
    "print(f\"  valuenum (non-null):           {valuenum_before:,}\")\n",
    "print(f\"  value_extracted (non-null):    {df['value_extracted'].notna().sum():,}\")\n",
    "print(f\"  Can be filled from extraction:  {value_extracted_only:,}\")\n",
    "\n",
    "# Merge: prefer valuenum, fallback to value_extracted\n",
    "df['valuenum_merged'] = df['valuenum'].fillna(df['value_extracted'])\n",
    "\n",
    "valuenum_after = df['valuenum_merged'].notna().sum()\n",
    "newly_filled = valuenum_after - valuenum_before\n",
    "\n",
    "print(f\"\\nAfter merge:\")\n",
    "print(f\"  valuenum_merged (non-null):   {valuenum_after:,}\")\n",
    "print(f\"  Newly filled from extraction:   {newly_filled:,} (+{(newly_filled/len(df)*100):.2f}%)\")\n",
    "print(f\"  Total improvement:              {valuenum_after - df['valuenum'].isna().sum():,} rows\")\n",
    "\n",
    "print(f\"\\nData type: {df['valuenum_merged'].dtype}\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(df['valuenum_merged'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4c190b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 5: SHOW BEFORE/AFTER EXAMPLES\n",
      "================================================================================\n",
      "\n",
      "Total newly filled rows: 1,311\n",
      "\n",
      "BEFORE → AFTER Examples:\n",
      "\n",
      "Original value       Extracted       valuenum (before)    valuenum_merged (after)\n",
      "───────────────────────────────────────────────────────────────────────────\n",
      "0-2                  1.000           NaN                  1.000               \n",
      "0-2                  1.000           NaN                  1.000               \n",
      "0-2                  1.000           NaN                  1.000               \n",
      "6-10                 8.000           NaN                  8.000               \n",
      "0-2                  1.000           NaN                  1.000               \n",
      "11-20                15.500          NaN                  15.500              \n",
      "0-2                  1.000           NaN                  1.000               \n",
      "0-2                  1.000           NaN                  1.000               \n",
      "3-5                  4.000           NaN                  4.000               \n",
      "0-2                  1.000           NaN                  1.000               \n",
      "3-5                  4.000           NaN                  4.000               \n",
      "0-2                  1.000           NaN                  1.000               \n",
      "<1                   0.900           NaN                  0.900               \n",
      "0-2                  1.000           NaN                  1.000               \n",
      "3-5                  4.000           NaN                  4.000               \n",
      "0-2                  1.000           NaN                  1.000               \n",
      "6-10                 8.000           NaN                  8.000               \n",
      "10-40                25.000          NaN                  25.000              \n",
      "20/4.                5.000           NaN                  5.000               \n",
      "11-20                15.500          NaN                  15.500              \n",
      "\n",
      "───────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Coverage improvement:\n",
      "  Before: 92.73% coverage\n",
      "  After:  92.86% coverage\n",
      "  Gain:   0.13%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 5: SHOW BEFORE/AFTER EXAMPLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find rows that were newly filled\n",
    "newly_filled_rows = df[(df['valuenum'].isna()) & (df['value_extracted'].notna())].copy()\n",
    "\n",
    "print(f\"\\nTotal newly filled rows: {len(newly_filled_rows):,}\\n\")\n",
    "print(\"BEFORE → AFTER Examples:\\n\")\n",
    "print(f\"{'Original value':<20} {'Extracted':<15} {'valuenum (before)':<20} {'valuenum_merged (after)':<20}\")\n",
    "print(\"─\" * 75)\n",
    "\n",
    "for i, (idx, row) in enumerate(newly_filled_rows.head(20).iterrows()):\n",
    "    original = str(row['value'])[:19]\n",
    "    extracted = f\"{row['value_extracted']:.3f}\" if pd.notna(row['value_extracted']) else \"NaN\"\n",
    "    before = \"NaN\"\n",
    "    after = f\"{row['valuenum_merged']:.3f}\"\n",
    "    \n",
    "    print(f\"{original:<20} {extracted:<15} {before:<20} {after:<20}\")\n",
    "\n",
    "print(f\"\\n{'─'*75}\")\n",
    "print(f\"\\nCoverage improvement:\")\n",
    "print(f\"  Before: {(df['valuenum'].notna().sum() / len(df) * 100):.2f}% coverage\")\n",
    "print(f\"  After:  {(df['valuenum_merged'].notna().sum() / len(df) * 100):.2f}% coverage\")\n",
    "print(f\"  Gain:   {(newly_filled / len(df) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b0a28aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 978501 entries, 0 to 978502\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   hadm_id            978501 non-null  float64\n",
      " 1   charttime          978501 non-null  object \n",
      " 2   value              863304 non-null  object \n",
      " 3   valuenum           907317 non-null  float64\n",
      " 4   valueuom           884585 non-null  object \n",
      " 5   ref_range_lower    865544 non-null  float64\n",
      " 6   ref_range_upper    865544 non-null  float64\n",
      " 7   flag               343687 non-null  object \n",
      " 8   label              978501 non-null  object \n",
      " 9   fluid              978501 non-null  object \n",
      " 10  examination_group  978501 non-null  object \n",
      " 11  analysis_batch_id  978501 non-null  object \n",
      " 12  qc_flag            978501 non-null  object \n",
      " 13  ref_range          146215 non-null  object \n",
      " 14  value_extracted    840559 non-null  float64\n",
      " 15  valuenum_merged    908628 non-null  float64\n",
      "dtypes: float64(6), object(10)\n",
      "memory usage: 126.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2122f9",
   "metadata": {},
   "source": [
    " ## Convert datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a7be8e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charttime: parsed 978501 values, 0 NaT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charttime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978498</th>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978499</th>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978500</th>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978501</th>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978502</th>\n",
       "      <td>2145-08-02 08:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>978501 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 charttime\n",
       "0      2188-01-04 23:43:00\n",
       "1      2188-01-04 23:43:00\n",
       "2      2188-01-04 23:43:00\n",
       "3      2188-01-05 06:56:00\n",
       "4      2188-01-05 06:56:00\n",
       "...                    ...\n",
       "978498 2145-08-02 08:30:00\n",
       "978499 2145-08-02 08:30:00\n",
       "978500 2145-08-02 08:30:00\n",
       "978501 2145-08-02 08:30:00\n",
       "978502 2145-08-02 08:30:00\n",
       "\n",
       "[978501 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ['charttime',]  \n",
    "\n",
    "for col in cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        print(f\"{col}: parsed {df[col].notna().sum()} values, {df[col].isna().sum()} NaT\")\n",
    "\n",
    "display(df[[c for c in df.columns if c in cols]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b75dde",
   "metadata": {},
   "source": [
    "## Little intermed inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39680cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 978503 entries, 0 to 978502\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   hadm_id            978503 non-null  float64       \n",
      " 1   charttime          978503 non-null  datetime64[ns]\n",
      " 2   value              839248 non-null  object        \n",
      " 3   valuenum           907317 non-null  float64       \n",
      " 4   valueuom           884585 non-null  object        \n",
      " 5   ref_range_lower    865544 non-null  float64       \n",
      " 6   ref_range_upper    865544 non-null  float64       \n",
      " 7   flag               343687 non-null  object        \n",
      " 8   label              978503 non-null  object        \n",
      " 9   fluid              978503 non-null  object        \n",
      " 10  examination_group  978503 non-null  object        \n",
      " 11  analysis_batch_id  978503 non-null  object        \n",
      " 12  qc_flag            978503 non-null  object        \n",
      " 13  ref_range          146215 non-null  object        \n",
      " 14  value_extracted    839248 non-null  float64       \n",
      " 15  value_numeric      907317 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), object(9)\n",
      "memory usage: 119.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f06a9f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "      <th>fluid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.00</td>\n",
       "      <td>IU/L</td>\n",
       "      <td>29.0</td>\n",
       "      <td>201.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creatine Kinase (CK)</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>ng/mL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creatine Kinase, MB Isoenzyme</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-04 23:43:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>ng/mL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Troponin T</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.10</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>INR(PT)</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.80</td>\n",
       "      <td>sec</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.50</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>PT</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>85.8</td>\n",
       "      <td>85.80</td>\n",
       "      <td>sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.50</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>PTT</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.10</td>\n",
       "      <td>%</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.90</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>% Hemoglobin A1c</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186.00</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>91.0</td>\n",
       "      <td>123.00</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>eAG</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anion Gap</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29654838.0</td>\n",
       "      <td>2188-01-05 06:56:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>mEq/L</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>Bicarbonate</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id           charttime value  valuenum valueuom  ref_range_lower  \\\n",
       "0  29654838.0 2188-01-04 23:43:00   NaN    198.00     IU/L             29.0   \n",
       "1  29654838.0 2188-01-04 23:43:00   5.0      5.00    ng/mL              0.0   \n",
       "2  29654838.0 2188-01-04 23:43:00   NaN      0.03    ng/mL              0.0   \n",
       "3  29654838.0 2188-01-05 06:56:00   1.2      1.20      NaN              0.9   \n",
       "4  29654838.0 2188-01-05 06:56:00  12.8     12.80      sec              9.4   \n",
       "5  29654838.0 2188-01-05 06:56:00  85.8     85.80      sec             25.0   \n",
       "6  29654838.0 2188-01-05 06:56:00   NaN      8.10        %              4.8   \n",
       "7  29654838.0 2188-01-05 06:56:00   NaN    186.00    mg/dL             91.0   \n",
       "8  29654838.0 2188-01-05 06:56:00  19.0     19.00    mEq/L              8.0   \n",
       "9  29654838.0 2188-01-05 06:56:00  20.0     20.00    mEq/L             22.0   \n",
       "\n",
       "   ref_range_upper      flag                          label  fluid  \n",
       "0           201.00       NaN           Creatine Kinase (CK)  Blood  \n",
       "1            10.00       NaN  Creatine Kinase, MB Isoenzyme  Blood  \n",
       "2             0.01  abnormal                     Troponin T  Blood  \n",
       "3             1.10  abnormal                        INR(PT)  Blood  \n",
       "4            12.50  abnormal                             PT  Blood  \n",
       "5            36.50  abnormal                            PTT  Blood  \n",
       "6             5.90  abnormal               % Hemoglobin A1c  Blood  \n",
       "7           123.00  abnormal                            eAG  Blood  \n",
       "8            20.00       NaN                      Anion Gap  Blood  \n",
       "9            32.00  abnormal                    Bicarbonate  Blood  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[:10]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[10:]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fe8c4a",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "399c23ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'value': 139255 missing values\n",
      "Column 'valuenum': 71186 missing values\n",
      "Column 'valueuom': 93918 missing values\n",
      "Column 'ref_range_lower': 112959 missing values\n",
      "Column 'ref_range_upper': 112959 missing values\n",
      "Column 'flag': 634816 missing values\n",
      "Column 'ref_range': 832288 missing values\n",
      "Column 'value_extracted': 139255 missing values\n",
      "Column 'value_numeric': 71186 missing values\n"
     ]
    }
   ],
   "source": [
    "# print sum of all missing values per column\n",
    "for col in df.columns:\n",
    "    missing_count = df[col].isna().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"Column '{col}': {missing_count} missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177338c",
   "metadata": {},
   "source": [
    "- no dod entry means not dead?  => convert to has_died variable\n",
    "- for xray, cath, ecg, ... => combine to one/two variable anyways (0/1 or 0/6), missing means this test was not performed\n",
    ". chief complaint and invasions are text columns => dismiss anyways\n",
    "- anchor_year: ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d589a52",
   "metadata": {},
   "source": [
    "## Do scatterpltos / distr / etc to check for dataqualtiy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd09bf1",
   "metadata": {},
   "source": [
    "### Do correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b6b13",
   "metadata": {},
   "source": [
    "## Non numerical correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152419f4",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{DATA_DIR}/heart_diagnoses_1_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a37114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load already cleaned to skip first steps\n",
    "#df = pd.read_csv(f\"{DATA_DIR}/heart_diagnoses_1_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab9cf62",
   "metadata": {},
   "source": [
    "## add subject id from df1, df3, and df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378c899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df2de0cb",
   "metadata": {},
   "source": [
    "## Create features and slim version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201280fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim[df_slim.columns[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim[df_slim.columns[10:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25385824",
   "metadata": {},
   "source": [
    "### Create features\n",
    "- var for exams\n",
    "- var for charttime?\n",
    "- var for dod (is_dead?), anchor_year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create is_dead variable from dod\n",
    "df_slim['is_dead'] = df_slim['dod'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create: A total exam count variable n_imaging_tests out of 'X-ray', 'CT', 'Ultrasound', 'CATH', 'ECG', 'MRI' (text columns, np.nan means no exam done)\n",
    "# Define exam columns\n",
    "exam_cols = ['X-ray', 'CT', 'Ultrasound', 'CATH', 'ECG', 'MRI']\n",
    "exam_cols = [col for col in exam_cols if col in df_slim.columns]\n",
    "\n",
    "# 1. TOTAL EXAM COUNT: n_imaging_tests\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE 1: Total Exam Count (n_imaging_tests)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_slim['n_imaging_tests'] = df_slim[exam_cols].notna().sum(axis=1)\n",
    "\n",
    "print(f\"\\nDistribution of total exams:\")\n",
    "print(df_slim['n_imaging_tests'].value_counts().sort_index())\n",
    "print(f\"\\nStatistics:\")\n",
    "print(df_slim['n_imaging_tests'].describe())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1 = axes[0]\n",
    "ax1.hist(df_slim['n_imaging_tests'], bins=range(0, 8), edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax1.set_xlabel('Number of Imaging Tests', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Distribution: Total Number of Imaging Tests', fontsize=13, fontweight='bold')\n",
    "ax1.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Bar plot with percentages\n",
    "ax2 = axes[1]\n",
    "counts = df_slim['n_imaging_tests'].value_counts().sort_index()\n",
    "percentages = (counts / len(df_slim) * 100).round(2)\n",
    "bars = ax2.bar(counts.index, counts.values, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for i, (idx, count) in enumerate(counts.items()):\n",
    "    pct = percentages[idx]\n",
    "    ax2.text(idx, count + 5, f'{pct}%', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax2.set_xlabel('Number of Imaging Tests', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Count & Percentage: Imaging Tests per Patient', fontsize=13, fontweight='bold')\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'../plots/1.1_df1_imaging_tests_count.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create: (has_radiology_exam, has_cardiac_exam): Radiology = X-ray + CT + MRI + Ultrasound Cardiac diagnostics = ECG + CATH variable out of 'X-ray', 'CT', 'Ultrasound', 'CATH', 'ECG', 'MRI' (text columns, np.nan means no exam done)\n",
    "\n",
    "# 2. CATEGORICAL FEATURES: has_radiology_exam, has_cardiac_exam\n",
    "# Radiology exams: X-ray, CT, MRI, Ultrasound\n",
    "radiology_cols = ['X-ray', 'CT', 'MRI', 'Ultrasound']\n",
    "radiology_cols = [col for col in radiology_cols if col in df_slim.columns]\n",
    "\n",
    "# Cardiac exams: ECG, CATH\n",
    "cardiac_cols = ['ECG', 'CATH']\n",
    "cardiac_cols = [col for col in cardiac_cols if col in df_slim.columns]\n",
    "\n",
    "df_slim['has_radiology_exam'] = df_slim[radiology_cols].notna().any(axis=1).astype(int)\n",
    "df_slim['has_cardiac_exam'] = df_slim[cardiac_cols].notna().any(axis=1).astype(int)\n",
    "\n",
    "# Combine for exam_type: 0=none, 1=radiology only, 2=cardiac only, 3=both\n",
    "df_slim['exam_type'] = (\n",
    "    (df_slim['has_radiology_exam'].astype(int) * 1) + \n",
    "    (df_slim['has_cardiac_exam'].astype(int) * 2)\n",
    ")\n",
    "\n",
    "exam_type_map = {\n",
    "    0: 'No Exams',\n",
    "    1: 'Radiology Only',\n",
    "    2: 'Cardiac Only',\n",
    "    3: 'Both Radiology & Cardiac'\n",
    "}\n",
    "df_slim['exam_type_label'] = df_slim['exam_type'].map(exam_type_map)\n",
    "\n",
    "print(f\"\\nRadiology columns: {radiology_cols}\")\n",
    "print(f\"Cardiac columns: {cardiac_cols}\\n\")\n",
    "\n",
    "print(\"has_radiology_exam distribution:\")\n",
    "print(df_slim['has_radiology_exam'].value_counts())\n",
    "print(f\"  → {(df_slim['has_radiology_exam'] == 1).sum()} patients ({(df_slim['has_radiology_exam'].mean()*100):.1f}%) had radiology exams\\n\")\n",
    "\n",
    "print(\"has_cardiac_exam distribution:\")\n",
    "print(df_slim['has_cardiac_exam'].value_counts())\n",
    "print(f\"  → {(df_slim['has_cardiac_exam'] == 1).sum()} patients ({(df_slim['has_cardiac_exam'].mean()*100):.1f}%) had cardiac exams\\n\")\n",
    "\n",
    "print(\"exam_type (combined) distribution:\")\n",
    "print(df_slim['exam_type_label'].value_counts())\n",
    "print(f\"\\nBreakdown:\")\n",
    "for exam_type in sorted(df_slim['exam_type'].unique()):\n",
    "    count = (df_slim['exam_type'] == exam_type).sum()\n",
    "    pct = (count / len(df_slim)) * 100\n",
    "    print(f\"  {exam_type_map[exam_type]:25s}: {count:5d} ({pct:5.1f}%)\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# # Plot 1: Radiology exam distribution\n",
    "# ax1 = axes[0, 0]\n",
    "# radiology_counts = df_slim['has_radiology_exam'].value_counts().sort_index()\n",
    "# colors_rad = ['#ff6b6b', '#51cf66']\n",
    "# # Use .iloc for positional indexing, or access by value: radiology_counts[0], radiology_counts[1]\n",
    "# ax1.bar(['No Radiology', 'Has Radiology'], \n",
    "#         [radiology_counts.iloc[0], radiology_counts.iloc[1]], \n",
    "#         color=colors_rad, edgecolor='black', alpha=0.7, linewidth=2)\n",
    "# for i, v in enumerate([radiology_counts.iloc[0], radiology_counts.iloc[1]]):\n",
    "#     pct = (v / len(df_slim)) * 100\n",
    "#     ax1.text(i, v + 20, f'{v}\\n({pct:.1f}%)', ha='center', fontsize=11, fontweight='bold')\n",
    "# ax1.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "# ax1.set_title('Radiology Exams: X-ray, CT, MRI, Ultrasound', fontsize=13, fontweight='bold')\n",
    "# ax1.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: Cardiac exam distribution\n",
    "ax2 = axes[0, 1]\n",
    "cardiac_counts = df_slim['has_cardiac_exam'].value_counts().sort_index()\n",
    "colors_card = ['#ff6b6b', '#4c6ef5']\n",
    "ax2.bar(['No Cardiac', 'Has Cardiac'], \n",
    "        [cardiac_counts.iloc[0], cardiac_counts.iloc[1]], \n",
    "        color=colors_card, edgecolor='black', alpha=0.7, linewidth=2)\n",
    "for i, v in enumerate([cardiac_counts.iloc[0], cardiac_counts.iloc[1]]):\n",
    "    pct = (v / len(df_slim)) * 100\n",
    "    ax2.text(i, v + 20, f'{v}\\n({pct:.1f}%)', ha='center', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Cardiac Exams: ECG, CATH', fontsize=13, fontweight='bold')\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "# Plot 3: Combined exam type distribution\n",
    "ax3 = axes[1, 0]\n",
    "exam_type_counts = df_slim['exam_type_label'].value_counts().sort_index()\n",
    "colors_combined = ['#ced4da', '#51cf66', '#4c6ef5', '#ffd43b']\n",
    "bars = ax3.bar(range(len(exam_type_counts)), exam_type_counts.values, \n",
    "               color=colors_combined, edgecolor='black', alpha=0.7, linewidth=2)\n",
    "ax3.set_xticks(range(len(exam_type_counts)))\n",
    "ax3.set_xticklabels(exam_type_counts.index, rotation=45, ha='right')\n",
    "ax3.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Exam Type Categories (Combined)', fontsize=13, fontweight='bold')\n",
    "ax3.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Add count and percentage labels\n",
    "for i, (idx, v) in enumerate(exam_type_counts.items()):\n",
    "    pct = (v / len(df_slim)) * 100\n",
    "    ax3.text(i, v + 10, f'{v}\\n({pct:.1f}%)', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 4: Summary statistics table\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "EXAM FEATURES SUMMARY\n",
    "\n",
    "Total Patients: {len(df_slim):,}\n",
    "\n",
    "n_imaging_tests (count):\n",
    "  • Mean: {df_slim['n_imaging_tests'].mean():.2f}\n",
    "  • Median: {df_slim['n_imaging_tests'].median():.0f}\n",
    "  • Min-Max: {df_slim['n_imaging_tests'].min():.0f} - {df_slim['n_imaging_tests'].max():.0f}\n",
    "  • Patients with NO exams: {(df_slim['n_imaging_tests'] == 0).sum()} ({(df_slim['n_imaging_tests'] == 0).mean()*100:.1f}%)\n",
    "  • Patients with ALL 6 exams: {(df_slim['n_imaging_tests'] == 6).sum()} ({(df_slim['n_imaging_tests'] == 6).mean()*100:.1f}%)\n",
    "\n",
    "has_radiology_exam:\n",
    "  • Yes: {(df_slim['has_radiology_exam'] == 1).sum()} ({(df_slim['has_radiology_exam'].mean()*100):.1f}%)\n",
    "  • No: {(df_slim['has_radiology_exam'] == 0).sum()} ({((1-df_slim['has_radiology_exam'].mean())*100):.1f}%)\n",
    "\n",
    "has_cardiac_exam:\n",
    "  • Yes: {(df_slim['has_cardiac_exam'] == 1).sum()} ({(df_slim['has_cardiac_exam'].mean()*100):.1f}%)\n",
    "  • No: {(df_slim['has_cardiac_exam'] == 0).sum()} ({((1-df_slim['has_cardiac_exam'].mean())*100):.1f}%)\n",
    "\n",
    "exam_type (combined):\n",
    "  • {exam_type_map[0]}: {(df_slim['exam_type'] == 0).sum()} ({(df_slim['exam_type'] == 0).mean()*100:.1f}%)\n",
    "  • {exam_type_map[1]}: {(df_slim['exam_type'] == 1).sum()} ({(df_slim['exam_type'] == 1).mean()*100:.1f}%)\n",
    "  • {exam_type_map[2]}: {(df_slim['exam_type'] == 2).sum()} ({(df_slim['exam_type'] == 2).mean()*100:.1f}%)\n",
    "  • {exam_type_map[3]}: {(df_slim['exam_type'] == 3).sum()} ({(df_slim['exam_type'] == 3).mean()*100:.1f}%)\n",
    "\"\"\"\n",
    "\n",
    "ax4.text(0.1, 0.95, summary_text, transform=ax4.transAxes, fontsize=10,\n",
    "         verticalalignment='top', family='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'../plots/1.1_df1_exam_features_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 3. INDIVIDUAL EXAM FLAGS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE 3: Individual Exam Flags (0/1)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in exam_cols:\n",
    "    df_slim[f'has_{col.lower()}'] = df_slim[col].notna().astype(int)\n",
    "    count = (df_slim[f'has_{col.lower()}'] == 1).sum()\n",
    "    pct = (count / len(df_slim)) * 100\n",
    "    print(f\"  has_{col.lower():12s}: {count:5d} ({pct:5.1f}%)\")\n",
    "\n",
    "# 4. CROSS-TABULATION: Exam types by gender and age group\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXAM PATTERNS BY DEMOGRAPHIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create age groups\n",
    "df_slim['age_group'] = pd.cut(df_slim['age'], bins=[0, 30, 50, 70, 120], \n",
    "                               labels=['<30', '30-50', '50-70', '70+'])\n",
    "\n",
    "print(\"\\nExam Type Distribution by Gender:\")\n",
    "print(pd.crosstab(df_slim['gender'], df_slim['exam_type_label'], margins=True))\n",
    "\n",
    "print(\"\\nExam Type Distribution by Age Group:\")\n",
    "print(pd.crosstab(df_slim['age_group'], df_slim['exam_type_label'], margins=True))\n",
    "\n",
    "# Chi-square test\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2_gender, p_gender, dof_gender, expected_gender = chi2_contingency(\n",
    "    pd.crosstab(df_slim['gender'], df_slim['exam_type'])\n",
    ")\n",
    "print(f\"\\nChi-square test (Gender × Exam Type): χ² = {chi2_gender:.4f}, p = {p_gender:.4e}\")\n",
    "\n",
    "chi2_age, p_age, dof_age, expected_age = chi2_contingency(\n",
    "    pd.crosstab(df_slim['age_group'], df_slim['exam_type'])\n",
    ")\n",
    "print(f\"Chi-square test (Age Group × Exam Type): χ² = {chi2_age:.4f}, p = {p_age:.4e}\")\n",
    "\n",
    "# Visualize cross-tabulation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# By gender\n",
    "ax1 = axes[0]\n",
    "crosstab_gender = pd.crosstab(df_slim['gender'], df_slim['exam_type_label'], normalize='index') * 100\n",
    "crosstab_gender.plot(kind='bar', ax=ax1, color=['#ced4da', '#51cf66', '#4c6ef5', '#ffd43b'], \n",
    "                     edgecolor='black', alpha=0.8, linewidth=1.5)\n",
    "ax1.set_xlabel('Gender', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Exam Type Distribution by Gender (χ² p-value: {:.4e})'.format(p_gender), \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax1.legend(title='Exam Type', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "ax1.grid(alpha=0.3, axis='y')\n",
    "plt.setp(ax1.get_xticklabels(), rotation=0)\n",
    "\n",
    "# By age group\n",
    "ax2 = axes[1]\n",
    "crosstab_age = pd.crosstab(df_slim['age_group'], df_slim['exam_type_label'], normalize='index') * 100\n",
    "crosstab_age.plot(kind='bar', ax=ax2, color=['#ced4da', '#51cf66', '#4c6ef5', '#ffd43b'], \n",
    "                  edgecolor='black', alpha=0.8, linewidth=1.5)\n",
    "ax2.set_xlabel('Age Group', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Exam Type Distribution by Age Group (χ² p-value: {:.4e})'.format(p_age), \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax2.legend(title='Exam Type', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'../plots/1.1_df1_exam_patterns_demographic.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEW FEATURES CREATED\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nColumns added to df_slim:\")\n",
    "new_cols = ['n_imaging_tests', 'has_radiology_exam', 'has_cardiac_exam', \n",
    "            'exam_type', 'exam_type_label', 'age_group',\n",
    "            'has_x-ray', 'has_ct', 'has_ultrasound', 'has_cath', 'has_ecg', 'has_mri']\n",
    "new_cols = [col for col in new_cols if col in df_slim.columns]\n",
    "for col in new_cols:\n",
    "    print(f\"  ✓ {col}: {df_slim[col].dtype}\")\n",
    "\n",
    "print(f\"\\ndf_slim shape: {df_slim.shape}\")\n",
    "print(f\"df_slim.info():\")\n",
    "print(df_slim[['n_imaging_tests', 'has_radiology_exam', 'has_cardiac_exam', 'exam_type_label', 'age_group']].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49df480",
   "metadata": {},
   "source": [
    "### Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CORRELATION MATRIX ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_cols = df_slim.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nNumeric columns found: {numeric_cols}\")\n",
    "print(f\"Total numeric columns: {len(numeric_cols)}\\n\")\n",
    "\n",
    "if len(numeric_cols) > 1:\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df_slim[numeric_cols].corr()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CORRELATION MATRIX\")\n",
    "    print(\"=\"*80)\n",
    "    print(correlation_matrix.round(3))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Plot 1: Full correlation heatmap\n",
    "    ax1 = axes[0]\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                annot=True, \n",
    "                fmt='.2f', \n",
    "                cmap='coolwarm', \n",
    "                center=0,\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={'label': 'Correlation Coefficient'},\n",
    "                ax=ax1)\n",
    "    ax1.set_title('Full Correlation Matrix Heatmap', fontsize=14, fontweight='bold')\n",
    "    plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "    plt.setp(ax1.get_yticklabels(), rotation=0)\n",
    "    \n",
    "    # Plot 2: Mask for upper triangle (cleaner view)\n",
    "    ax2 = axes[1]\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                annot=True, \n",
    "                fmt='.2f', \n",
    "                cmap='coolwarm', \n",
    "                center=0,\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                mask=mask,\n",
    "                cbar_kws={'label': 'Correlation Coefficient'},\n",
    "                ax=ax2)\n",
    "    ax2.set_title('Lower Triangle Correlation Matrix (Unique Pairs)', fontsize=14, fontweight='bold')\n",
    "    plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "    plt.setp(ax2.get_yticklabels(), rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Extract strong correlations (> 0.5 or < -0.5, excluding diagonal)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STRONG CORRELATIONS (|r| > 0.5, excluding self-correlations)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    strong_corr = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_value = correlation_matrix.iloc[i, j]\n",
    "            if abs(corr_value) > 0.5:\n",
    "                strong_corr.append({\n",
    "                    'Variable 1': correlation_matrix.columns[i],\n",
    "                    'Variable 2': correlation_matrix.columns[j],\n",
    "                    'Correlation': corr_value,\n",
    "                    'Strength': 'Strong Positive' if corr_value > 0 else 'Strong Negative'\n",
    "                })\n",
    "    \n",
    "    if strong_corr:\n",
    "        strong_corr_df = pd.DataFrame(strong_corr).sort_values('Correlation', key=abs, ascending=False)\n",
    "        print(f\"\\nFound {len(strong_corr)} strong correlations:\\n\")\n",
    "        print(strong_corr_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nNo correlations with |r| > 0.5 found\")\n",
    "    \n",
    "    # Moderate correlations (0.3 to 0.5)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODERATE CORRELATIONS (0.3 < |r| ≤ 0.5)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    moderate_corr = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_value = correlation_matrix.iloc[i, j]\n",
    "            if 0.3 < abs(corr_value) <= 0.5:\n",
    "                moderate_corr.append({\n",
    "                    'Variable 1': correlation_matrix.columns[i],\n",
    "                    'Variable 2': correlation_matrix.columns[j],\n",
    "                    'Correlation': corr_value,\n",
    "                    'Strength': 'Moderate Positive' if corr_value > 0 else 'Moderate Negative'\n",
    "                })\n",
    "    \n",
    "    if moderate_corr:\n",
    "        moderate_corr_df = pd.DataFrame(moderate_corr).sort_values('Correlation', key=abs, ascending=False)\n",
    "        print(f\"\\nFound {len(moderate_corr)} moderate correlations:\\n\")\n",
    "        print(moderate_corr_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nNo moderate correlations found (0.3 < |r| ≤ 0.5)\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get correlation values (excluding diagonal)\n",
    "    corr_values = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            corr_values.append(correlation_matrix.iloc[i, j])\n",
    "    \n",
    "    corr_values = np.array(corr_values)\n",
    "    print(f\"\\nMean correlation: {corr_values.mean():.3f}\")\n",
    "    print(f\"Median correlation: {np.median(corr_values):.3f}\")\n",
    "    print(f\"Std Dev: {corr_values.std():.3f}\")\n",
    "    print(f\"Min: {corr_values.min():.3f}\")\n",
    "    print(f\"Max: {corr_values.max():.3f}\")\n",
    "    \n",
    "    # Distribution of correlations\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.hist(corr_values, bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax.axvline(corr_values.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {corr_values.mean():.3f}')\n",
    "    ax.axvline(np.median(corr_values), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(corr_values):.3f}')\n",
    "    ax.set_xlabel('Correlation Coefficient', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Distribution of Correlation Coefficients', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('correlation_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Not enough numeric columns for correlation analysis\")\n",
    "    print(f\"Found only {len(numeric_cols)} numeric column(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12962fd4",
   "metadata": {},
   "source": [
    "### Dropunused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02125343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim.columns, len(df_slim.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e4847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP: 'note_id', 'note_type', 'note_seq', 'subject_id_dx', 'storetime', 'HPI', 'physical_exam', 'chief_complaint', 'invasions', 'X-ray', 'CT', 'Ultrasound', 'CATH', 'MRI', 'reports', 'subject_id_dx',  'anchor_year', 'dod', 'has_x-ray', 'has_ct', 'has_ultrasound', 'has_cath', 'has_ecg', 'has_mri', 'age_group'\n",
    "\n",
    "# keep 'subject_id', 'hadm_id' , icd_code, 'ECG' (for later task 3), charttime\n",
    "df_slim.drop(columns=[ 'note_id', 'note_type', 'note_seq', 'subject_id_dx', 'storetime', 'HPI', 'physical_exam', 'chief_complaint', 'invasions', 'X-ray', 'CT', 'Ultrasound', 'CATH', 'MRI', 'reports', 'subject_id_dx',  'anchor_year', 'dod', 'has_x-ray', 'has_ct', 'has_ultrasound', 'has_cath', 'has_ecg', 'has_mri', 'age_group'], inplace=True)\n",
    "df_slim.columns, len(df_slim.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02161030",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim[['exam_type', 'exam_type_label']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23eae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim['has_cardiac_exam'].value_counts(), df_slim['has_radiology_exam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad427d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim['exam_type_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96570cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim['is_dead'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67181e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim.drop(columns=['long_title', 'has_radiology_exam' ], inplace=True)\n",
    "df_slim.columns, len(df_slim.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406495ef",
   "metadata": {},
   "source": [
    "## Save SLim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d353275",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slim.to_csv(f\"{DATA_DIR}/heart_diagnoses_1_cleaned_slim.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdebcaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4reg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
