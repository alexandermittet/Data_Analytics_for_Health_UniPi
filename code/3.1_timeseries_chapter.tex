\chapter{Time Series Preprocessing}

In this chapter, we outline the preprocessing pipeline applied to the ECG time series data extracted from the cardiovascular cohort. The preprocessing steps are essential for preparing the raw physiological signals for downstream clustering and classification tasks. All ECG recordings were obtained from WFDB-formatted 12-lead ECG data, with the Lead II channel selected as the primary signal for analysis due to its clinical utility in rhythm assessment and its consistent visibility of cardiac electrical activity.

%%%%%%%%%%%%%%%
\section{Data Overview}

The ECG dataset comprises 1,786 patients with complete Lead II recordings. Each recording contains 5,000 samples collected over a 10-second window at a sampling frequency of 500 Hz, resulting in a total of 8.93 million signal samples. The raw ECG signals exhibit typical characteristics of clinical recordings: baseline wander, powerline interference, and amplitude variations across patients.

\begin{table}[h!]
\centering
\small
\begin{tabular}{lr}
\hline
\textbf{Property} & \textbf{Value} \\ \hline
Total Patients & 1,786 \\
ECG Channel & Lead II \\
Sampling Frequency & 500 Hz \\
Signal Duration & 10 seconds \\
Samples per Patient & 5,000 \\
Total Samples & 8,930,000 \\
Mean Signal Amplitude & 0.01 mV \\
Signal Std Deviation & 0.16 mV \\
Signal Range & -1.53 to 2.27 mV \\ \hline
\end{tabular}
\caption{ECG time series dataset characteristics.}
\label{tab:ecg_overview}
\end{table}

%%%%%%%%%%%%%%%
\section{Preprocessing Pipeline}

To ensure comparability across patients and remove artifacts that could confound downstream analysis, we applied a five-step preprocessing pipeline. The pipeline addresses common challenges in ECG signal processing: baseline drift, amplitude normalization, linear trends, and noise contamination.

The preprocessing sequence consists of: (1) \textit{offset translation removal}, which centers each signal around zero by subtracting the mean value; (2) \textit{amplitude scaling} via z-normalization, standardizing the variance to unity; (3) \textit{linear trend removal} using polynomial detrending to eliminate slow baseline drift; (4) \textit{ECG bandpass filtering} (0.5--40 Hz) to remove baseline wander and high-frequency noise while preserving the clinically relevant frequency components of the ECG signal; and (5) \textit{notch filtering} at 60 Hz to eliminate powerline interference common in hospital environments.

Figure~\ref{fig:preprocessing_steps} illustrates the sequential transformation of a representative ECG signal through each preprocessing stage. The final preprocessed signal exhibits a stable baseline, reduced noise, and enhanced visibility of cardiac waveform components (P, QRS, T complexes) compared to the raw recording.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{plots/3.1_preprocessing_steps.jpg}
    \caption{Sequential preprocessing steps applied to an ECG Lead II signal (Subject 14582002). From top left to bottom right: original signal, offset removal, amplitude scaling, trend removal, ECG filtering (bandpass + notch), and final comparison.}
    \label{fig:preprocessing_steps}
\end{figure}

%%%%%%%%%%%%%%%
\section{Dimensionality Reduction with Piecewise Aggregate Approximation}

To enable efficient clustering analysis while preserving the essential morphological characteristics of the ECG signals, we applied Piecewise Aggregate Approximation (PAA). PAA reduces the dimensionality of each 5,000-sample time series by dividing the signal into equal-length segments and computing the mean value within each segment. This approach achieves a compression ratio of 500:1, reducing each signal to 10 representative segments while maintaining the overall trend and amplitude characteristics.

Figure~\ref{fig:paa_approximation} demonstrates the PAA transformation for four representative patients. The step-function approximation captures the general morphology and amplitude variations of the original preprocessed signals, making it suitable for distance-based clustering algorithms that require fixed-length feature vectors.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{plots/3.1_paa_approximation.jpg}
    \caption{Piecewise Aggregate Approximation (PAA) applied to four representative ECG time series. Each signal is compressed from 5,000 samples to 10 segments (500:1 compression ratio) while preserving the overall signal morphology.}
    \label{fig:paa_approximation}
\end{figure}

%%%%%%%%%%%%%%%
\section{Feature Extraction}

In addition to the PAA representation, we extracted 13 statistical features from each preprocessed time series to capture complementary aspects of signal behavior. These features include basic statistics (mean, variance, standard deviation, min, max, range, median), trend characteristics (slope and intercept from linear regression), temporal dependencies (lag-1 autocovariance), and distributional properties (25th and 75th percentiles, interquartile range).

The distributions of nine key features across the cohort, shown in Figure~\ref{fig:features_distribution}, reveal that most signals exhibit near-zero means (reflecting successful centering), standardized variances clustered around unity (confirming effective normalization), and minimal linear trends. The autocovariance values are consistently high (mean 0.87), indicating strong temporal correlation characteristic of ECG signals.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{plots/3.1_features_distribution.jpg}
    \caption{Distribution of nine key statistical features extracted from preprocessed ECG time series across 1,786 patients. Each subplot shows the distribution of feature values (e.g., mean, variance, range) computed from individual patient ECG signals.}
    \label{fig:features_distribution}
\end{figure}

The preprocessed time series data, along with the PAA approximations and extracted features, serve as the foundation for the clustering analysis presented in Chapter 5 and the time series classification tasks in Chapter 6.

