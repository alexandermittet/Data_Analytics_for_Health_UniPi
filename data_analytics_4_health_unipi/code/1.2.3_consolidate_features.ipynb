{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Analytics for Health - Task 1.2.3: Feature Consolidation\n",
        "\n",
        "## Overview\n",
        "This notebook consolidates all features computed at admission level (hadm_id, subject_id), then aggregates them to subject_id level to create the final patient profile with ~10 features.\n",
        "\n",
        "## Objectives\n",
        "- Compute admission-level features for all datasets\n",
        "- Aggregate admission-level features to subject_id level\n",
        "- Add additional features to reach ~10 total features\n",
        "- Create final patient profile dataset\n",
        "\n",
        "## Approach\n",
        "1. Compute all features per admission (hadm_id, subject_id)\n",
        "2. Aggregate admission-level features to subject_id level\n",
        "3. Merge all features on subject_id\n",
        "4. Save consolidated patient profile\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully\n",
            "Data path: /Users/alexandermittet/Library/Mobile Documents/com~apple~CloudDocs/uni_life/UniPi DAD/data_analytics_4_health_unipi/Data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up file paths\n",
        "notebook_dir = Path.cwd().resolve()\n",
        "data_path = (notebook_dir / '..' / 'Data').resolve()\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "print(f\"Data path: {data_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Raw Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Heart Diagnoses: 4,864 rows × 25 columns\n",
            "Loaded Laboratory Events: 978,503 rows × 14 columns\n",
            "Loaded Microbiology Events: 15,587 rows × 14 columns\n",
            "Loaded Procedure Codes: 14,497 rows × 6 columns\n",
            "\n",
            "All datasets loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Load all four datasets\n",
        "df1 = pd.read_csv(data_path / 'heart_diagnoses_1.csv')  # Heart Diagnoses\n",
        "df2 = pd.read_csv(data_path / 'laboratory_events_codes_2.csv')  # Laboratory Events\n",
        "df3 = pd.read_csv(data_path / 'microbiology_events_codes_3.csv')  # Microbiology Events\n",
        "df4 = pd.read_csv(data_path / 'procedure_code_4.csv')  # Procedure Codes\n",
        "\n",
        "print(f\"Loaded Heart Diagnoses: {df1.shape[0]:,} rows × {df1.shape[1]} columns\")\n",
        "print(f\"Loaded Laboratory Events: {df2.shape[0]:,} rows × {df2.shape[1]} columns\")\n",
        "print(f\"Loaded Microbiology Events: {df3.shape[0]:,} rows × {df3.shape[1]} columns\")\n",
        "print(f\"Loaded Procedure Codes: {df4.shape[0]:,} rows × {df4.shape[1]} columns\")\n",
        "print(\"\\nAll datasets loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Clean Data: Remove Problematic hadm_ids\n",
        "\n",
        "Remove hadm_ids that map to multiple subject_ids to ensure data integrity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data cleaning completed!\n",
            "df1: 4,660 rows (removed 204 problematic rows)\n",
            "df3: 11,459 rows (removed 4,128 problematic rows)\n",
            "df4: 14,497 rows (removed 0 problematic rows)\n"
          ]
        }
      ],
      "source": [
        "# Function to clean datasets: remove hadm_ids with multiple subject_ids\n",
        "def clean_df(df):\n",
        "    \"\"\"Remove rows where hadm_id maps to multiple subject_ids\"\"\"\n",
        "    if 'hadm_id' in df.columns and 'subject_id' in df.columns:\n",
        "        # Count unique subject_ids per hadm_id\n",
        "        counts = df.groupby('hadm_id')['subject_id'].nunique()\n",
        "        # Keep only hadm_ids with exactly one subject_id\n",
        "        valid_hadm = counts[counts == 1].index\n",
        "        return df[df['hadm_id'].isin(valid_hadm)].copy()\n",
        "    return df.copy()\n",
        "\n",
        "# Clean all datasets\n",
        "df1_clean = clean_df(df1)\n",
        "df2_clean = df2.copy()  # df2 doesn't have subject_id yet\n",
        "df3_clean = clean_df(df3)\n",
        "df4_clean = clean_df(df4)\n",
        "\n",
        "print(\"Data cleaning completed!\")\n",
        "print(f\"df1: {len(df1_clean):,} rows (removed {len(df1) - len(df1_clean):,} problematic rows)\")\n",
        "print(f\"df3: {len(df3_clean):,} rows (removed {len(df3) - len(df3_clean):,} problematic rows)\")\n",
        "print(f\"df4: {len(df4_clean):,} rows (removed {len(df4) - len(df4_clean):,} problematic rows)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Reference Table for hadm_id → subject_id Mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reference table: 4,711 unique (hadm_id, subject_id) pairs\n",
            "Unique hadm_ids: 4,711\n",
            "Unique subject_ids: 4,244\n"
          ]
        }
      ],
      "source": [
        "# Create reference table for hadm_id -> subject_id mapping\n",
        "ref_table = pd.concat([\n",
        "    df1_clean[['hadm_id', 'subject_id']].drop_duplicates(),\n",
        "    df3_clean[['hadm_id', 'subject_id']].drop_duplicates()\n",
        "]).drop_duplicates()\n",
        "\n",
        "print(f\"Reference table: {len(ref_table):,} unique (hadm_id, subject_id) pairs\")\n",
        "print(f\"Unique hadm_ids: {ref_table['hadm_id'].nunique():,}\")\n",
        "print(f\"Unique subject_ids: {ref_table['subject_id'].nunique():,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compute Admission-Level Features\n",
        "\n",
        "### 4.1 Laboratory Features per Admission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df2 (Labs) after adding subject_id: 971,633 / 978,503 rows have subject_id\n",
            "Working with 971,633 lab events with valid subject_id\n"
          ]
        }
      ],
      "source": [
        "# Add subject_id to df2 (Labs) - it only has hadm_id\n",
        "df2_with_subject = df2_clean.merge(ref_table, on='hadm_id', how='left')\n",
        "print(f\"df2 (Labs) after adding subject_id: {df2_with_subject['subject_id'].notna().sum():,} / {len(df2_with_subject):,} rows have subject_id\")\n",
        "\n",
        "# Remove rows without subject_id\n",
        "df2_with_subject = df2_with_subject[df2_with_subject['subject_id'].notna()].copy()\n",
        "print(f\"Working with {len(df2_with_subject):,} lab events with valid subject_id\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature 1 - n_lab_events: 4,702 admissions\n",
            "            hadm_id    subject_id  n_lab_events\n",
            "count  4.702000e+03  4.702000e+03   4702.000000\n",
            "mean   2.502633e+07  1.500560e+07    206.642493\n",
            "std    2.868247e+06  2.881679e+06    242.259902\n",
            "min    2.000446e+07  1.000098e+07      3.000000\n",
            "25%    2.262870e+07  1.246864e+07     79.000000\n",
            "50%    2.504050e+07  1.498441e+07    134.000000\n",
            "75%    2.747417e+07  1.750755e+07    248.000000\n",
            "max    2.999967e+07  1.999850e+07   4591.000000\n"
          ]
        }
      ],
      "source": [
        "# Feature 1: Total count of laboratory events per admission\n",
        "lab_count_per_adm = df2_with_subject.groupby(['hadm_id', 'subject_id']).size().reset_index(name='n_lab_events')\n",
        "print(f\"Feature 1 - n_lab_events: {len(lab_count_per_adm):,} admissions\")\n",
        "print(lab_count_per_adm.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature 2 - abnormal_ratio: 4,702 admissions\n",
            "            hadm_id    subject_id  abnormal_ratio\n",
            "count  4.702000e+03  4.702000e+03     4702.000000\n",
            "mean   2.502633e+07  1.500560e+07        0.309212\n",
            "std    2.868247e+06  2.881679e+06        0.116179\n",
            "min    2.000446e+07  1.000098e+07        0.000000\n",
            "25%    2.262870e+07  1.246864e+07        0.231752\n",
            "50%    2.504050e+07  1.498441e+07        0.311666\n",
            "75%    2.747417e+07  1.750755e+07        0.390623\n",
            "max    2.999967e+07  1.999850e+07        1.000000\n"
          ]
        }
      ],
      "source": [
        "# Feature 2: Ratio of abnormal tests per admission\n",
        "df2_with_subject['is_abnormal'] = df2_with_subject['flag'].str.contains('abnormal', case=False, na=False)\n",
        "abnormal_ratio_per_adm = df2_with_subject.groupby(['hadm_id', 'subject_id'])['is_abnormal'].mean().reset_index(name='abnormal_ratio')\n",
        "print(f\"Feature 2 - abnormal_ratio: {len(abnormal_ratio_per_adm):,} admissions\")\n",
        "print(abnormal_ratio_per_adm.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature 3 - max_glucose: 4,677 admissions with glucose measurements\n",
            "            hadm_id    subject_id  max_glucose\n",
            "count  4.677000e+03  4.677000e+03  4674.000000\n",
            "mean   2.502625e+07  1.500462e+07   180.003851\n",
            "std    2.869366e+06  2.884325e+06   123.341160\n",
            "min    2.000446e+07  1.000098e+07    46.000000\n",
            "25%    2.262667e+07  1.246802e+07   115.000000\n",
            "50%    2.503418e+07  1.498146e+07   147.000000\n",
            "75%    2.747503e+07  1.751445e+07   199.000000\n",
            "max    2.999967e+07  1.999850e+07  1190.000000\n"
          ]
        }
      ],
      "source": [
        "# Feature 3: Maximum glucose value per admission\n",
        "glucose_df = df2_with_subject[df2_with_subject['label'].str.contains('glucose', case=False, na=False)]\n",
        "max_glucose_per_adm = glucose_df.groupby(['hadm_id', 'subject_id'])['valuenum'].max().reset_index(name='max_glucose')\n",
        "print(f\"Feature 3 - max_glucose: {len(max_glucose_per_adm):,} admissions with glucose measurements\")\n",
        "print(max_glucose_per_adm.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean creatinine: 4,689 admissions\n",
            "Mean hemoglobin: 4,669 admissions\n",
            "\n",
            "Final lab features shape: (4702, 7)\n",
            "Admissions with lab data: 4,702\n"
          ]
        }
      ],
      "source": [
        "# Feature 4: Additional lab features - Mean creatinine and hemoglobin per admission\n",
        "creatinine_df = df2_with_subject[df2_with_subject['label'].str.contains('creatinine', case=False, na=False)]\n",
        "hemoglobin_df = df2_with_subject[df2_with_subject['label'].str.contains('hemoglobin', case=False, na=False)]\n",
        "\n",
        "lab_features_adm = []\n",
        "if len(creatinine_df) > 0:\n",
        "    mean_creatinine = creatinine_df.groupby(['hadm_id', 'subject_id'])['valuenum'].mean().reset_index(name='mean_creatinine')\n",
        "    lab_features_adm.append(mean_creatinine)\n",
        "    print(f\"Mean creatinine: {len(mean_creatinine):,} admissions\")\n",
        "\n",
        "if len(hemoglobin_df) > 0:\n",
        "    mean_hemoglobin = hemoglobin_df.groupby(['hadm_id', 'subject_id'])['valuenum'].mean().reset_index(name='mean_hemoglobin')\n",
        "    lab_features_adm.append(mean_hemoglobin)\n",
        "    print(f\"Mean hemoglobin: {len(mean_hemoglobin):,} admissions\")\n",
        "\n",
        "# Merge all lab features\n",
        "lab_features = lab_count_per_adm.merge(abnormal_ratio_per_adm, on=['hadm_id', 'subject_id'], how='outer')\n",
        "lab_features = lab_features.merge(max_glucose_per_adm, on=['hadm_id', 'subject_id'], how='outer')\n",
        "\n",
        "if len(lab_features_adm) > 0:\n",
        "    for feature_df in lab_features_adm:\n",
        "        lab_features = lab_features.merge(feature_df, on=['hadm_id', 'subject_id'], how='outer')\n",
        "\n",
        "print(f\"\\nFinal lab features shape: {lab_features.shape}\")\n",
        "print(f\"Admissions with lab data: {len(lab_features):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Microbiology Features per Admission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature 5 - n_micro_exam: 2,198 admissions\n",
            "            hadm_id    subject_id  n_micro_exam\n",
            "count  2.198000e+03  2.198000e+03   2198.000000\n",
            "mean   2.503509e+07  1.504292e+07      5.213376\n",
            "std    2.885937e+06  2.845304e+06      6.923173\n",
            "min    2.001360e+07  1.000098e+07      1.000000\n",
            "25%    2.259458e+07  1.260172e+07      1.000000\n",
            "50%    2.511358e+07  1.501327e+07      3.000000\n",
            "75%    2.750232e+07  1.751577e+07      7.000000\n",
            "max    2.999967e+07  1.999737e+07    107.000000\n"
          ]
        }
      ],
      "source": [
        "# Feature 5: Total count of microbiology examinations per admission\n",
        "micro_count_per_adm = df3_clean.groupby(['hadm_id', 'subject_id']).size().reset_index(name='n_micro_exam')\n",
        "print(f\"Feature 5 - n_micro_exam: {len(micro_count_per_adm):,} admissions\")\n",
        "print(micro_count_per_adm.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature 6 - n_positive_micro: 2,198 admissions\n",
            "            hadm_id    subject_id  n_positive_micro\n",
            "count  2.198000e+03  2.198000e+03            2198.0\n",
            "mean   2.503509e+07  1.504292e+07               0.0\n",
            "std    2.885937e+06  2.845304e+06               0.0\n",
            "min    2.001360e+07  1.000098e+07               0.0\n",
            "25%    2.259458e+07  1.260172e+07               0.0\n",
            "50%    2.511358e+07  1.501327e+07               0.0\n",
            "75%    2.750232e+07  1.751577e+07               0.0\n",
            "max    2.999967e+07  1.999737e+07               0.0\n",
            "\n",
            "Final micro features shape: (2198, 4)\n"
          ]
        }
      ],
      "source": [
        "# Feature 6: Count of positive microbiology results per admission\n",
        "# Check if there's a column indicating positive results\n",
        "if 'interpretation' in df3_clean.columns:\n",
        "    df3_clean['is_positive'] = df3_clean['interpretation'].str.contains('positive', case=False, na=False)\n",
        "    positive_count = df3_clean.groupby(['hadm_id', 'subject_id'])['is_positive'].sum().reset_index(name='n_positive_micro')\n",
        "    print(f\"Feature 6 - n_positive_micro: {len(positive_count):,} admissions\")\n",
        "    print(positive_count.describe())\n",
        "    \n",
        "    # Merge microbiology features\n",
        "    micro_features = micro_count_per_adm.merge(positive_count, on=['hadm_id', 'subject_id'], how='outer')\n",
        "else:\n",
        "    micro_features = micro_count_per_adm.copy()\n",
        "    print(\"No 'interpretation' column found, skipping positive count feature\")\n",
        "\n",
        "print(f\"\\nFinal micro features shape: {micro_features.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Procedure Features per Admission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature 7 - total_procedures: 3,459 admissions\n",
            "            hadm_id    subject_id  total_procedures\n",
            "count  3.459000e+03  3.459000e+03       3459.000000\n",
            "mean   2.502943e+07  1.499381e+07          4.191096\n",
            "std    2.853466e+06  2.868527e+06          2.989024\n",
            "min    2.000790e+07  1.000098e+07          1.000000\n",
            "25%    2.264270e+07  1.249509e+07          2.000000\n",
            "50%    2.506423e+07  1.495295e+07          3.000000\n",
            "75%    2.747180e+07  1.747168e+07          6.000000\n",
            "max    2.999967e+07  1.999850e+07         28.000000\n"
          ]
        }
      ],
      "source": [
        "# Feature 7: Total count of procedures per admission\n",
        "proc_count_per_adm = df4_clean.groupby(['hadm_id', 'subject_id']).size().reset_index(name='total_procedures')\n",
        "print(f\"Feature 7 - total_procedures: {len(proc_count_per_adm):,} admissions\")\n",
        "print(proc_count_per_adm.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature 8 - n_unique_procedures: 3,459 admissions\n",
            "            hadm_id    subject_id  n_unique_procedures\n",
            "count  3.459000e+03  3.459000e+03          3459.000000\n",
            "mean   2.502943e+07  1.499381e+07             4.058398\n",
            "std    2.853466e+06  2.868527e+06             2.717689\n",
            "min    2.000790e+07  1.000098e+07             1.000000\n",
            "25%    2.264270e+07  1.249509e+07             2.000000\n",
            "50%    2.506423e+07  1.495295e+07             3.000000\n",
            "75%    2.747180e+07  1.747168e+07             6.000000\n",
            "max    2.999967e+07  1.999850e+07            21.000000\n",
            "\n",
            "Final proc features shape: (3459, 4)\n"
          ]
        }
      ],
      "source": [
        "# Feature 8: Count of unique procedure types per admission\n",
        "if 'icd_code' in df4_clean.columns:\n",
        "    unique_proc_types = df4_clean.groupby(['hadm_id', 'subject_id'])['icd_code'].nunique().reset_index(name='n_unique_procedures')\n",
        "    print(f\"Feature 8 - n_unique_procedures: {len(unique_proc_types):,} admissions\")\n",
        "    print(unique_proc_types.describe())\n",
        "    \n",
        "    # Merge procedure features\n",
        "    proc_features = proc_count_per_adm.merge(unique_proc_types, on=['hadm_id', 'subject_id'], how='outer')\n",
        "else:\n",
        "    proc_features = proc_count_per_adm.copy()\n",
        "    print(\"No 'icd_code' column found, skipping unique procedure count\")\n",
        "\n",
        "print(f\"\\nFinal proc features shape: {proc_features.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Heart Diagnoses Features per Admission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Heart features (age, gender): 4,660 admissions\n",
            "            hadm_id    subject_id         age\n",
            "count  4.660000e+03  4.660000e+03  1326.00000\n",
            "mean   2.502295e+07  1.500005e+07    68.96908\n",
            "std    2.865917e+06  2.880019e+06    14.99554\n",
            "min    2.000446e+07  1.000098e+07    18.00000\n",
            "25%    2.263073e+07  1.247198e+07    60.00000\n",
            "50%    2.503405e+07  1.497279e+07    70.00000\n",
            "75%    2.746393e+07  1.749304e+07    81.00000\n",
            "max    2.999967e+07  1.999850e+07    95.00000\n"
          ]
        }
      ],
      "source": [
        "# Feature 9: Age and gender per admission (from df1)\n",
        "heart_features_adm = df1_clean[['hadm_id', 'subject_id', 'age', 'gender']].drop_duplicates(['hadm_id', 'subject_id']).copy()\n",
        "print(f\"Heart features (age, gender): {len(heart_features_adm):,} admissions\")\n",
        "print(heart_features_adm.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature 10 - n_diagnoses: 4,660 admissions\n",
            "            hadm_id    subject_id  n_diagnoses\n",
            "count  4.660000e+03  4.660000e+03       4660.0\n",
            "mean   2.502295e+07  1.500005e+07          1.0\n",
            "std    2.865917e+06  2.880019e+06          0.0\n",
            "min    2.000446e+07  1.000098e+07          1.0\n",
            "25%    2.263073e+07  1.247198e+07          1.0\n",
            "50%    2.503405e+07  1.497279e+07          1.0\n",
            "75%    2.746393e+07  1.749304e+07          1.0\n",
            "max    2.999967e+07  1.999850e+07          1.0\n",
            "\n",
            "Final heart features shape: (4660, 5)\n"
          ]
        }
      ],
      "source": [
        "# Feature 10: Diagnosis count per admission\n",
        "if 'icd_code' in df1_clean.columns:\n",
        "    diagnosis_count = df1_clean.groupby(['hadm_id', 'subject_id'])['icd_code'].count().reset_index(name='n_diagnoses')\n",
        "    print(f\"Feature 10 - n_diagnoses: {len(diagnosis_count):,} admissions\")\n",
        "    print(diagnosis_count.describe())\n",
        "    \n",
        "    # Merge heart features\n",
        "    heart_features = heart_features_adm.merge(diagnosis_count, on=['hadm_id', 'subject_id'], how='outer')\n",
        "else:\n",
        "    heart_features = heart_features_adm.copy()\n",
        "    print(\"No 'icd_code' column found, skipping diagnosis count\")\n",
        "\n",
        "print(f\"\\nFinal heart features shape: {heart_features.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Time Features per Admission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time features per admission: 4,864 admissions\n",
            "         subject_id       hadm_id  days_since_last_admission\n",
            "count  4.864000e+03  4.864000e+03                 472.000000\n",
            "mean   1.510717e+07  2.501745e+07                 533.220339\n",
            "std    2.938761e+06  2.873736e+06                 644.585515\n",
            "min    1.000098e+07  2.000446e+07                   2.000000\n",
            "25%    1.252385e+07  2.260252e+07                  70.750000\n",
            "50%    1.507553e+07  2.503238e+07                 273.000000\n",
            "75%    1.764939e+07  2.746833e+07                 716.250000\n",
            "max    1.999860e+07  2.999967e+07                3581.000000\n"
          ]
        }
      ],
      "source": [
        "# Load time features computed in previous notebook\n",
        "time_features_adm = pd.read_csv(data_path / '1.2_admission_time_features.csv')\n",
        "print(f\"Time features per admission: {len(time_features_adm):,} admissions\")\n",
        "print(time_features_adm.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Merge All Admission-Level Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Admission-level features shape: (4864, 15)\n",
            "\n",
            "Features: ['hadm_id', 'subject_id', 'n_lab_events', 'abnormal_ratio', 'max_glucose', 'mean_creatinine', 'mean_hemoglobin', 'n_micro_exam', 'n_positive_micro', 'total_procedures', 'n_unique_procedures', 'age', 'gender', 'n_diagnoses', 'days_since_last_admission']\n",
            "\n",
            "Missing values per column:\n",
            "hadm_id                         0\n",
            "subject_id                      0\n",
            "n_lab_events                  162\n",
            "abnormal_ratio                162\n",
            "max_glucose                   190\n",
            "mean_creatinine               175\n",
            "mean_hemoglobin               196\n",
            "n_micro_exam                 2666\n",
            "n_positive_micro             2666\n",
            "total_procedures             1405\n",
            "n_unique_procedures          1405\n",
            "age                          3538\n",
            "gender                       3538\n",
            "n_diagnoses                   204\n",
            "days_since_last_admission    4392\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Start with reference table as base\n",
        "admission_features = ref_table.copy()\n",
        "\n",
        "# Merge all feature datasets\n",
        "admission_features = admission_features.merge(lab_features, on=['hadm_id', 'subject_id'], how='outer')\n",
        "admission_features = admission_features.merge(micro_features, on=['hadm_id', 'subject_id'], how='outer')\n",
        "admission_features = admission_features.merge(proc_features, on=['hadm_id', 'subject_id'], how='outer')\n",
        "admission_features = admission_features.merge(heart_features, on=['hadm_id', 'subject_id'], how='outer')\n",
        "admission_features = admission_features.merge(time_features_adm, on=['hadm_id', 'subject_id'], how='outer')\n",
        "\n",
        "print(f\"Admission-level features shape: {admission_features.shape}\")\n",
        "print(f\"\\nFeatures: {admission_features.columns.tolist()}\")\n",
        "print(f\"\\nMissing values per column:\")\n",
        "print(admission_features.isna().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Aggregate Admission-Level Features to Subject Level\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregation strategy:\n",
            "  n_lab_events: sum\n",
            "  n_micro_exam: sum\n",
            "  total_procedures: sum\n",
            "  n_diagnoses: sum\n",
            "  n_positive_micro: sum\n",
            "  n_unique_procedures: sum\n",
            "  abnormal_ratio: mean\n",
            "  max_glucose: max\n",
            "  mean_creatinine: mean\n",
            "  mean_hemoglobin: mean\n",
            "  age: mean\n",
            "  gender: <function mode_func at 0x12961b940>\n",
            "  days_since_last_admission: mean\n"
          ]
        }
      ],
      "source": [
        "# Define aggregation strategy for each feature\n",
        "agg_dict = {}\n",
        "\n",
        "# Count features: sum across admissions\n",
        "count_features = ['n_lab_events', 'n_micro_exam', 'total_procedures', 'n_diagnoses']\n",
        "if 'n_positive_micro' in admission_features.columns:\n",
        "    count_features.append('n_positive_micro')\n",
        "if 'n_unique_procedures' in admission_features.columns:\n",
        "    count_features.append('n_unique_procedures')\n",
        "\n",
        "for feat in count_features:\n",
        "    if feat in admission_features.columns:\n",
        "        agg_dict[feat] = 'sum'\n",
        "\n",
        "# Ratio/mean features: mean across admissions\n",
        "ratio_features = ['abnormal_ratio']\n",
        "for feat in ratio_features:\n",
        "    if feat in admission_features.columns:\n",
        "        agg_dict[feat] = 'mean'\n",
        "\n",
        "# Max features: max across admissions\n",
        "max_features = ['max_glucose']\n",
        "for feat in max_features:\n",
        "    if feat in admission_features.columns:\n",
        "        agg_dict[feat] = 'max'\n",
        "\n",
        "# Mean features: mean across admissions\n",
        "mean_features = ['mean_creatinine', 'mean_hemoglobin']\n",
        "for feat in mean_features:\n",
        "    if feat in admission_features.columns:\n",
        "        agg_dict[feat] = 'mean'\n",
        "\n",
        "# Age: mean across admissions (or first if same)\n",
        "if 'age' in admission_features.columns:\n",
        "    agg_dict['age'] = 'mean'\n",
        "\n",
        "# Gender: mode (most common) across admissions\n",
        "if 'gender' in admission_features.columns:\n",
        "    def mode_func(x):\n",
        "        return x.mode()[0] if len(x.mode()) > 0 else None\n",
        "    agg_dict['gender'] = mode_func\n",
        "\n",
        "# Time features: mean across admissions\n",
        "if 'days_since_last_admission' in admission_features.columns:\n",
        "    agg_dict['days_since_last_admission'] = 'mean'\n",
        "\n",
        "print(\"Aggregation strategy:\")\n",
        "for feat, strategy in agg_dict.items():\n",
        "    print(f\"  {feat}: {strategy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject-level features shape: (4392, 14)\n",
            "\n",
            "Features: ['subject_id', 'gender', 'n_lab_events', 'n_micro_exam', 'total_procedures', 'n_diagnoses', 'n_positive_micro', 'n_unique_procedures', 'abnormal_ratio', 'max_glucose', 'mean_creatinine', 'mean_hemoglobin', 'age', 'days_since_last_admission']\n"
          ]
        }
      ],
      "source": [
        "# Aggregate to subject level\n",
        "subject_features_list = []\n",
        "\n",
        "# Handle gender separately (mode) - only if it exists in the dataframe\n",
        "if 'gender' in admission_features.columns:\n",
        "    gender_mode = admission_features.groupby('subject_id')['gender'].apply(lambda x: x.mode()[0] if len(x.mode()) > 0 else None).reset_index(name='gender')\n",
        "    subject_features_list.append(gender_mode)\n",
        "\n",
        "# Aggregate numeric features - create filtered agg_dict without gender\n",
        "numeric_features = [f for f in agg_dict.keys() if f != 'gender']\n",
        "numeric_agg_dict = {k: v for k, v in agg_dict.items() if k != 'gender'}\n",
        "\n",
        "if numeric_features:\n",
        "    # Only aggregate features that actually exist in the dataframe\n",
        "    available_numeric_features = [f for f in numeric_features if f in admission_features.columns]\n",
        "    if available_numeric_features:\n",
        "        available_agg_dict = {k: v for k, v in numeric_agg_dict.items() if k in available_numeric_features}\n",
        "        subject_features_numeric = admission_features.groupby('subject_id')[available_numeric_features].agg(available_agg_dict).reset_index()\n",
        "        subject_features_list.append(subject_features_numeric)\n",
        "\n",
        "# Merge all subject-level features\n",
        "if len(subject_features_list) > 0:\n",
        "    subject_features = subject_features_list[0]\n",
        "    for df in subject_features_list[1:]:\n",
        "        subject_features = subject_features.merge(df, on='subject_id', how='outer')\n",
        "else:\n",
        "    subject_features = admission_features.groupby('subject_id').first().reset_index()\n",
        "\n",
        "print(f\"Subject-level features shape: {subject_features.shape}\")\n",
        "print(f\"\\nFeatures: {subject_features.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Add Subject-Level Time Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject-level time features: 4,392 subjects\n",
            "['subject_id', 'n_total_admissions', 'days_since_last_admission']\n",
            "\n",
            "Final subject features shape: (4392, 16)\n",
            "Total features: 15\n"
          ]
        }
      ],
      "source": [
        "# Load subject-level time features\n",
        "time_features_subject = pd.read_csv(data_path / '1.2_subject_time_features.csv')\n",
        "print(f\"Subject-level time features: {len(time_features_subject):,} subjects\")\n",
        "print(time_features_subject.columns.tolist())\n",
        "\n",
        "# Merge with subject features\n",
        "subject_features = subject_features.merge(time_features_subject, on='subject_id', how='outer')\n",
        "\n",
        "print(f\"\\nFinal subject features shape: {subject_features.shape}\")\n",
        "print(f\"Total features: {len(subject_features.columns) - 1}\")  # -1 for subject_id\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Feature Summary and Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FINAL PATIENT PROFILE SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Total subjects: 4,392\n",
            "Total features: 15\n",
            "\n",
            "================================================================================\n",
            "FEATURE LIST:\n",
            "================================================================================\n",
            "1. gender\n",
            "2. n_lab_events\n",
            "3. n_micro_exam\n",
            "4. total_procedures\n",
            "5. n_diagnoses\n",
            "6. n_positive_micro\n",
            "7. n_unique_procedures\n",
            "8. abnormal_ratio\n",
            "9. max_glucose\n",
            "10. mean_creatinine\n",
            "11. mean_hemoglobin\n",
            "12. age\n",
            "13. days_since_last_admission_x\n",
            "14. n_total_admissions\n",
            "15. days_since_last_admission_y\n",
            "\n",
            "================================================================================\n",
            "MISSING VALUES:\n",
            "================================================================================\n",
            "                             Missing Count  Missing %\n",
            "days_since_last_admission_x           4001      91.10\n",
            "days_since_last_admission_y           4001      91.10\n",
            "gender                                3158      71.90\n",
            "age                                   3158      71.90\n",
            "mean_hemoglobin                        186       4.23\n",
            "max_glucose                            176       4.01\n",
            "mean_creatinine                        167       3.80\n",
            "abnormal_ratio                         155       3.53\n",
            "\n",
            "================================================================================\n",
            "FEATURE STATISTICS:\n",
            "================================================================================\n",
            "         subject_id  n_lab_events  n_micro_exam  total_procedures  \\\n",
            "count  4.392000e+03   4392.000000   4392.000000       4392.000000   \n",
            "mean   1.512674e+07    221.227914      2.609062          3.300774   \n",
            "std    2.945158e+06    269.658576      5.728181          3.461592   \n",
            "min    1.000098e+07      0.000000      0.000000          0.000000   \n",
            "25%    1.254920e+07     77.000000      0.000000          0.000000   \n",
            "50%    1.509920e+07    139.000000      0.000000          2.000000   \n",
            "75%    1.768003e+07    277.000000      3.000000          6.000000   \n",
            "max    1.999860e+07   4591.000000    107.000000         28.000000   \n",
            "\n",
            "       n_diagnoses  n_positive_micro  n_unique_procedures  abnormal_ratio  \\\n",
            "count   4392.00000            4392.0          4392.000000     4237.000000   \n",
            "mean       1.06102               0.0             3.196266        0.305360   \n",
            "std        0.43152               0.0             3.232324        0.114668   \n",
            "min        0.00000               0.0             0.000000        0.000000   \n",
            "25%        1.00000               0.0             0.000000        0.227273   \n",
            "50%        1.00000               0.0             2.000000        0.309091   \n",
            "75%        1.00000               0.0             5.000000        0.384615   \n",
            "max        5.00000               0.0            23.000000        1.000000   \n",
            "\n",
            "       max_glucose  mean_creatinine  mean_hemoglobin          age  \\\n",
            "count  4216.000000      4225.000000      4206.000000  1234.000000   \n",
            "mean    182.277277         3.632194        11.296951    68.833874   \n",
            "std     126.950465        10.437183         1.897090    14.954837   \n",
            "min      46.000000         0.142857         4.800000    18.000000   \n",
            "25%     115.000000         0.887500         9.866667    59.000000   \n",
            "50%     148.000000         1.125000        11.211688    70.000000   \n",
            "75%     202.000000         2.155000        12.633333    81.000000   \n",
            "max    1190.000000       288.323529        18.857143    95.000000   \n",
            "\n",
            "       days_since_last_admission_x  n_total_admissions  \\\n",
            "count                   391.000000         4392.000000   \n",
            "mean                    531.629156            1.107468   \n",
            "std                     619.454271            0.374936   \n",
            "min                       2.000000            1.000000   \n",
            "25%                      81.000000            1.000000   \n",
            "50%                     298.500000            1.000000   \n",
            "75%                     728.500000            1.000000   \n",
            "max                    3494.000000            5.000000   \n",
            "\n",
            "       days_since_last_admission_y  \n",
            "count                   391.000000  \n",
            "mean                    531.629156  \n",
            "std                     619.454271  \n",
            "min                       2.000000  \n",
            "25%                      81.000000  \n",
            "50%                     298.500000  \n",
            "75%                     728.500000  \n",
            "max                    3494.000000  \n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"FINAL PATIENT PROFILE SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTotal subjects: {len(subject_features):,}\")\n",
        "print(f\"Total features: {len(subject_features.columns) - 1}\")  # Excluding subject_id\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FEATURE LIST:\")\n",
        "print(\"=\"*80)\n",
        "feature_list = [col for col in subject_features.columns if col != 'subject_id']\n",
        "for i, feat in enumerate(feature_list, 1):\n",
        "    print(f\"{i}. {feat}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MISSING VALUES:\")\n",
        "print(\"=\"*80)\n",
        "missing = subject_features.isna().sum()\n",
        "missing_pct = (missing / len(subject_features) * 100).round(2)\n",
        "missing_df = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})\n",
        "print(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FEATURE STATISTICS:\")\n",
        "print(\"=\"*80)\n",
        "print(subject_features.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save Consolidated Patient Profile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved consolidated patient profile to: /Users/alexandermittet/Library/Mobile Documents/com~apple~CloudDocs/uni_life/UniPi DAD/data_analytics_4_health_unipi/Data/1.2.3_final_patient_profile.csv\n",
            "  Subjects: 4,392\n",
            "  Features: 15\n",
            "  File size: 386.93 KB\n"
          ]
        }
      ],
      "source": [
        "# Convert subject_id to integer (nullable)\n",
        "if 'subject_id' in subject_features.columns:\n",
        "    subject_features['subject_id'] = subject_features['subject_id'].astype('Int64')\n",
        "\n",
        "# Save consolidated profile\n",
        "output_file = data_path / '1.2.3_final_patient_profile.csv'\n",
        "subject_features.to_csv(output_file, index=False)\n",
        "print(f\"✓ Saved consolidated patient profile to: {output_file}\")\n",
        "print(f\"  Subjects: {len(subject_features):,}\")\n",
        "print(f\"  Features: {len(subject_features.columns) - 1}\")\n",
        "print(f\"  File size: {output_file.stat().st_size / 1024:.2f} KB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**Features Created (Admission-Level → Subject-Level):**\n",
        "\n",
        "1. **Laboratory Features:**\n",
        "   - `n_lab_events`: Total count of laboratory events (sum across admissions)\n",
        "   - `abnormal_ratio`: Ratio of abnormal tests (mean across admissions)\n",
        "   - `max_glucose`: Maximum glucose value (max across admissions)\n",
        "   - `mean_creatinine`: Mean creatinine value (mean across admissions, if available)\n",
        "   - `mean_hemoglobin`: Mean hemoglobin value (mean across admissions, if available)\n",
        "\n",
        "2. **Microbiology Features:**\n",
        "   - `n_micro_exam`: Total count of microbiology examinations (sum across admissions)\n",
        "   - `n_positive_micro`: Count of positive results (sum across admissions, if available)\n",
        "\n",
        "3. **Procedure Features:**\n",
        "   - `total_procedures`: Total count of procedures (sum across admissions)\n",
        "   - `n_unique_procedures`: Count of unique procedure types (sum across admissions, if available)\n",
        "\n",
        "4. **Heart Diagnoses Features:**\n",
        "   - `age`: Average age (mean across admissions)\n",
        "   - `gender`: First gender recorded (first value across admissions)\n",
        "   - `n_diagnoses`: Total diagnosis count (sum across admissions)\n",
        "\n",
        "5. **Time Features:**\n",
        "   - `n_total_admissions`: Total number of unique admissions per subject\n",
        "   - `days_since_last_admission`: Mean days between consecutive admissions\n",
        "\n",
        "**Total: 12 features**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "prop5",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
